{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zO4bRoxr2Apy"
      },
      "source": [
        "# **Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones**\n",
        "\n",
        "## **Edición 2023**\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "# Trabajo práctico entregable - parte 2\n",
        "\n",
        "\n",
        "En el ejercicio 1 de la parte 1 del entregable seleccionaron las filas y columnas relevantes al problema de predicción de precios de una propiedad. Además de ello, tuvieron que reducir el número de valores posibles para las variables categóricas utilizando información de dominio.\n",
        "\n",
        "En el ejercicio 2 de la parte 1 del entregable imputaron los valores faltantes de las columnas `Suburb` y las columnas obtenidas a partir del conjunto de datos `airbnb`.\n",
        "\n",
        "En esta notebook, **se utilizará resultado de dichas operaciones.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4udjxjk1EtVU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import pandas\n",
        "\n",
        "import seaborn\n",
        "seaborn.set_context('talk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "_qeFN3GnEvMk",
        "outputId": "02e6e659-1be0-414f-a6a0-8f8298bb84d7"
      },
      "outputs": [],
      "source": [
        "# Acá deberían leer el conjunto de datos que ya tienen.\n",
        "melb_df = pandas.read_csv(\n",
        "    'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/melb_data.csv')\n",
        "melb_df[:3]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s-mixICN22kA"
      },
      "source": [
        "## Ejercicio 1: Encoding\n",
        "\n",
        "1. Seleccionar todas las filas y columnas del conjunto de datos obtenido en la parte 1 del entregable, **excepto** `BuildingArea` y `YearBuilt`, que volveremos a imputar más adelante.\n",
        "\n",
        "2. Aplicar una codificación One-hot encoding a cada fila, tanto para variables numéricas como categóricas. Si lo consideran necesario, pueden volver a reducir el número de categorías únicas.\n",
        "\n",
        "Algunas opciones:\n",
        "  1. Utilizar `OneHotEncoder` junto con el parámetro `categories` para las variables categóricas y luego usar `numpy.hstack` para concatenar el resultado con las variables numéricas. \n",
        "  2. `DictVectorizer` con algunos pasos de pre-proceso previo.\n",
        "\n",
        "Recordar también que el atributo `pandas.DataFrame.values` permite acceder a la matriz de numpy subyacente a un DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_Qk43aLIl4d"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['Type']\n",
        "numerical_cols = ['Rooms']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSNfW1BBJnV0",
        "outputId": "10ac472d-62ef-4e9b-f66f-48af6797b3bc"
      },
      "outputs": [],
      "source": [
        "melb_df[categorical_cols].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPDDOVHNNywn",
        "outputId": "4c497064-cca1-4344-b5a1-e8521ecb4cbc"
      },
      "outputs": [],
      "source": [
        "# Check for nulls\n",
        "melb_df[categorical_cols].isna().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ismngxPcfoWb"
      },
      "source": [
        "## Ejercicio 2: Imputación por KNN\n",
        "\n",
        "En el teórico se presentó el método `IterativeImputer` para imputar valores faltantes en variables numéricas. Sin embargo, los ejemplos presentados sólo utilizaban algunas variables numéricas presentes en el conjunto de datos. En este ejercicio, utilizaremos la matriz de datos codificada para imputar datos faltantes de manera más precisa.\n",
        "\n",
        "1. Agregue a la matriz obtenida en el punto anterior las columnas `YearBuilt` y `BuildingArea`.\n",
        "2. Aplique una instancia de `IterativeImputer` con un estimador `KNeighborsRegressor` para imputar los valores de las variables. ¿Es necesario estandarizar o escalar los datos previamente?\n",
        "3. Realice un gráfico mostrando la distribución de cada variable antes de ser imputada, y con ambos métodos de imputación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ClSr_JapCw",
        "outputId": "9468199f-071a-4514-c62b-e161a6113f18"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "melb_data_mice = melb_df.copy(deep=True)\n",
        "\n",
        "mice_imputer = IterativeImputer(random_state=0, estimator=KNeighborsRegressor())\n",
        "melb_data_mice[['YearBuilt','BuildingArea']] = mice_imputer.fit_transform(\n",
        "    melb_data_mice[['YearBuilt', 'BuildingArea']])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ImjXQZUbVoKH"
      },
      "source": [
        "Ejemplo de gráfico comparando las distribuciones de datos obtenidas con cada método de imputación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "PMK1ktqYQTJK",
        "outputId": "b3ec0023-25cd-41ad-b069-cc59de7c2313"
      },
      "outputs": [],
      "source": [
        "mice_year_built = melb_data_mice.YearBuilt.to_frame()\n",
        "mice_year_built['Imputation'] = 'KNN over YearBuilt and BuildingArea'\n",
        "melb_year_build = melb_df.YearBuilt.dropna().to_frame()\n",
        "melb_year_build['Imputation'] = 'Original'\n",
        "data = pandas.concat([mice_year_built, melb_year_build])\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "g = seaborn.kdeplot(data=data, x='YearBuilt', hue='Imputation')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NBN7-5OIxjJW"
      },
      "source": [
        "## Ejercicio 3: Reducción de dimensionalidad.\n",
        "\n",
        "Utilizando la matriz obtenida en el ejercicio anterior:\n",
        "1. Aplique `PCA` para obtener $n$ componentes principales de la matriz, donde `n = min(20, X.shape[0])`. ¿Es necesario estandarizar o escalar los datos?\n",
        "2. Grafique la varianza capturada por los primeros $n$ componentes principales, para cada $n$.\n",
        "3. En base al gráfico, seleccione las primeras $m$ columnas de la matriz transformada para agregar como nuevas características al conjunto de datos."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WrZTYmG_ZyDy"
      },
      "source": [
        "## Ejercicio 4: Composición del resultado\n",
        "\n",
        "Transformar nuevamente el conjunto de datos procesado en un `pandas.DataFrame` y guardarlo en un archivo.\n",
        "\n",
        "Para eso, será necesario recordar el nombre original de cada columna de la matriz, en el orden correcto. Tener en cuenta:\n",
        "1. El método `OneHotEncoder.get_feature_names` o el atributo `OneHotEncoder.categories_` permiten obtener una lista con los valores de la categoría que le corresponde a cada índice de la matriz.\n",
        "2. Ninguno de los métodos aplicados intercambia de lugar las columnas o las filas de la matriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "DfchYPgTxvQ4",
        "outputId": "c0bd0b28-1cb8-419c-e799-631045735021"
      },
      "outputs": [],
      "source": [
        "## Small example\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "## If we process our data with the following steps:\n",
        "categorical_cols = ['Type', 'Regionname']\n",
        "numerical_cols = ['Rooms', 'Distance']\n",
        "new_columns = []\n",
        "\n",
        "# Step 1: encode categorical columns\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "X_cat = encoder.fit_transform(melb_df[categorical_cols])\n",
        "for col, col_values in zip(categorical_cols, encoder.categories_):\n",
        "  for col_value in col_values:\n",
        "    new_columns.append('{}={}'.format(col, col_value))\n",
        "print(\"Matrix has shape {}, with columns: {}\".format(X_cat.shape, new_columns))\n",
        "\n",
        "# Step 2: Append the numerical columns\n",
        "X = numpy.hstack([X_cat, melb_df[numerical_cols].values])\n",
        "new_columns.extend(numerical_cols)\n",
        "print(\"Matrix has shape {}, with columns: {}\".format(X_cat.shape, new_columns))\n",
        "\n",
        "# Step 3: Append some new features, like PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_dummy_features = pca.fit_transform(X)\n",
        "X_pca = numpy.hstack([X, pca_dummy_features])\n",
        "new_columns.extend(['pca1', 'pca2'])\n",
        "\n",
        "## Re-build dataframe\n",
        "processed_melb_df = pandas.DataFrame(data=X_pca, columns=new_columns)\n",
        "processed_melb_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mVBLFc8PhRtW"
      },
      "source": [
        "## Ejercicio 5: Documentación\n",
        "\n",
        "En un documento `.pdf` o `.md` realizar un reporte de las operaciones que realizaron para obtener el conjunto de datos final. Se debe incluir:\n",
        "  1. Criterios de exclusión (o inclusión) de filas\n",
        "  2. Interpretación de las columnas presentes\n",
        "  2. Todas las transofrmaciones realizadas\n",
        "\n",
        "Este documento es de uso técnico exclusivamente, y su objetivo es permitir que otres desarrolladores puedan reproducir los mismos pasos y obtener el mismo resultado. Debe ser detallado pero consiso. Por ejemplo:\n",
        "\n",
        "```\n",
        "  ## Criterios de exclusión de ejemplos\n",
        "  1. Se eliminan ejemplos donde el año de construcción es previo a 1900\n",
        "\n",
        "  ## Características seleccionadas\n",
        "  ### Características categóricas\n",
        "  1. Type: tipo de propiedad. 3 valores posibles\n",
        "  2. ...\n",
        "  Todas las características categóricas fueron codificadas con un\n",
        "  método OneHotEncoding utilizando como máximo sus 30 valores más \n",
        "  frecuentes.\n",
        "  \n",
        "  ### Características numéricas\n",
        "  1. Rooms: Cantidad de habitaciones\n",
        "  2. Distance: Distancia al centro de la ciudad.\n",
        "  3. airbnb_mean_price: Se agrega el precio promedio diario de \n",
        "     publicaciones de la plataforma AirBnB en el mismo código \n",
        "     postal. [Link al repositorio con datos externos].\n",
        "\n",
        "  ### Transformaciones:\n",
        "  1. Todas las características numéricas fueron estandarizadas.\n",
        "  2. La columna `Suburb` fue imputada utilizando el método ...\n",
        "  3. Las columnas `YearBuilt` y ... fueron imputadas utilizando el \n",
        "     algoritmo ...\n",
        "  4. ...\n",
        "\n",
        "  ### Datos aumentados\n",
        "  1. Se agregan las 5 primeras columnas obtenidas a través del\n",
        "     método de PCA, aplicado sobre el conjunto de datos\n",
        "     totalmente procesado.\n",
        "```\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq7nuPg2HIYx"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
