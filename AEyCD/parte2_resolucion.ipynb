{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"zO4bRoxr2Apy"},"source":["# **Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones**\n","\n","## **Edición 2023**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uuCQ5s6ThQAD"},"source":["## Análisis exploratorio y curación de datos\n","\n","### Trabajo práctico entregable - Grupo 22 - Parte 2\n","\n","**Integrantes:**\n","- Chevallier-Boutell, Ignacio José\n","- Ribetto, Federico Daniel\n","- Rosa, Santiago\n","- Spano, Marcelo\n","\n","**Seguimiento:** Meinardi, Vanesa\n","\n","---"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OLdL2xV7hQAE"},"source":["## Librerías"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4udjxjk1EtVU","outputId":"6ad1d1f1-0b37-426c-a0c2-e0277e6b6e26"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.width', 1000)\n","pd.options.mode.chained_assignment = None  # default='warn'\n","\n","import seaborn as sns\n","sns.set_context('talk')\n","sns.set_theme(style='white')\n","\n","from sklearn.preprocessing import OneHotEncoder"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Acerca del dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Utilizaremos el conjunto de datos con el que terminamos la parte 1 del entregable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"_qeFN3GnEvMk","outputId":"02e6e659-1be0-414f-a6a0-8f8298bb84d7"},"outputs":[],"source":["df = pd.read_csv('GuardadoFinal.csv')\n","df[:3]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# Ejercicio 1 - Encoding"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"s-mixICN22kA"},"source":["En la mayoría de los modelos de machinelearning es necesario que las variables que se utilizan para entrenarlo sean del tipo numéricas. Es por eso que se debe encontrar una forma de tratar a las variables numéricas. \n","\n","En este caso las variables categóricas que consideramos importantes para la predicción del precio de las casas son CouncilArea, Regionname, SellerG y Type. Las 4 son variables nominales ya que no tienen un orden en sus categorías. Es por eso que consideramos que One Hot Encoding es un buen algoritmo para realizar su codificación.\n","\n","Este algoritmo crea una columna para cada una de las categorías que posee cada una de las variables consideradas. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhgll7-IhQAG"},"outputs":[],"source":["# Separamos las variables categóricas y numéricas\n","categorical_cols = ['CouncilArea', 'Regionname', 'SellerG', 'Type']\n","numerical_cols = [x for x in df.columns if (x not in categorical_cols) and x not in ['Postcode', 'zipcode']]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cgkZJ6KLhQAG"},"source":["Veamos la cantidad de categorías que posee cada una de las variables categóricas y el número de columnas que se creará en total luego de realizar One Hot Encoding."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSNfW1BBJnV0","outputId":"10ac472d-62ef-4e9b-f66f-48af6797b3bc"},"outputs":[],"source":["print('Cantidad de categorías para cada variable:')\n","print(df[categorical_cols].nunique())\n","print('')\n","print('Cantidad de columnas que se creará con One Hot Encoding:', df[categorical_cols].nunique().sum())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"n8-A1qhrhQAG"},"source":["A continuación se utiliza la función OneHotEncoder de sklearn para realizar el One Hot Encoding de las variables.\n","\n","Se crea un dataframe de pandas con las nuevas columnas, una para cada categoría."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlrOCwUKhQAG","outputId":"97250a8b-d84d-468d-f93c-e313204f9e7c"},"outputs":[],"source":["features = df[categorical_cols]\n","\n","categories = [features[column].unique() for column in features.columns]\n","encoder = OneHotEncoder(categories=categories)\n","encoded_features = encoder.fit_transform(features)\n","\n","# Create new column names\n","feature_names = []\n","for i, column in enumerate(features.columns):\n","    for category in categories[i]:\n","        feature_names.append(f'{column}_{category}')\n","\n","encoded_df = pd.DataFrame(encoded_features.toarray(), columns=feature_names)\n","encoded_df[:3]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZMQD6WwchQAH"},"source":["Se realiza la unión de las variables numéricas con las categóricas codificadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWtvUQ4FhQAH"},"outputs":[],"source":["new_df = pd.concat([encoded_df, df[numerical_cols]], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CyJ6J72GhQAH","outputId":"e31d7dc2-c6f5-4758-bb9e-05e8444daf13"},"outputs":[],"source":["new_df[:3]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# Ejercicio 2 - Imputación por KNN"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ismngxPcfoWb"},"source":["En el teórico se presentó el método `IterativeImputer` para imputar valores faltantes en variables numéricas. Sin embargo, los ejemplos presentados sólo utilizaban algunas variables numéricas presentes en el conjunto de datos. En este ejercicio, utilizaremos la matriz de datos codificada para imputar datos faltantes de manera más precisa.\n","\n","1. Agregue a la matriz obtenida en el punto anterior las columnas `YearBuilt` y `BuildingArea`.\n","2. Aplique una instancia de `IterativeImputer` con un estimador `KNeighborsRegressor` para imputar los valores de las variables. ¿Es necesario estandarizar o escalar los datos previamente?\n","3. Realice un gráfico mostrando la distribución de cada variable antes de ser imputada, y con ambos métodos de imputación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G4ClSr_JapCw"},"outputs":[],"source":["from sklearn.experimental import enable_iterative_imputer\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.impute import IterativeImputer\n","\n","melb_data_mice = melb_df.copy(deep=True)\n","\n","mice_imputer = IterativeImputer(random_state=0, estimator=KNeighborsRegressor())\n","melb_data_mice[['YearBuilt','BuildingArea']] = mice_imputer.fit_transform(\n","    melb_data_mice[['YearBuilt', 'BuildingArea']])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ImjXQZUbVoKH"},"source":["Ejemplo de gráfico comparando las distribuciones de datos obtenidas con cada método de imputación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMK1ktqYQTJK"},"outputs":[],"source":["mice_year_built = melb_data_mice.YearBuilt.to_frame()\n","mice_year_built['Imputation'] = 'KNN over YearBuilt and BuildingArea'\n","melb_year_build = melb_df.YearBuilt.dropna().to_frame()\n","melb_year_build['Imputation'] = 'Original'\n","data = pandas.concat([mice_year_built, melb_year_build])\n","fig = plt.figure(figsize=(8, 5))\n","g = seaborn.kdeplot(data=data, x='YearBuilt', hue='Imputation')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# Ejercicio 3 - Reducción de dimensionalidad."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NBN7-5OIxjJW"},"source":["Utilizando la matriz obtenida en el ejercicio anterior:\n","1. Aplique `PCA` para obtener $n$ componentes principales de la matriz, donde `n = min(20, X.shape[0])`. ¿Es necesario estandarizar o escalar los datos?\n","2. Grafique la varianza capturada por los primeros $n$ componentes principales, para cada $n$.\n","3. En base al gráfico, seleccione las primeras $m$ columnas de la matriz transformada para agregar como nuevas características al conjunto de datos."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# Ejercicio 4 - Composición del resultado"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WrZTYmG_ZyDy"},"source":["Transformar nuevamente el conjunto de datos procesado en un `pandas.DataFrame` y guardarlo en un archivo.\n","\n","Para eso, será necesario recordar el nombre original de cada columna de la matriz, en el orden correcto. Tener en cuenta:\n","1. El método `OneHotEncoder.get_feature_names` o el atributo `OneHotEncoder.categories_` permiten obtener una lista con los valores de la categoría que le corresponde a cada índice de la matriz.\n","2. Ninguno de los métodos aplicados intercambia de lugar las columnas o las filas de la matriz."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfchYPgTxvQ4"},"outputs":[],"source":["## Small example\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import OneHotEncoder\n","\n","## If we process our data with the following steps:\n","categorical_cols = ['Type', 'Regionname']\n","numerical_cols = ['Rooms', 'Distance']\n","new_columns = []\n","\n","# Step 1: encode categorical columns\n","encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","X_cat = encoder.fit_transform(melb_df[categorical_cols])\n","for col, col_values in zip(categorical_cols, encoder.categories_):\n","  for col_value in col_values:\n","    new_columns.append('{}={}'.format(col, col_value))\n","print(\"Matrix has shape {}, with columns: {}\".format(X_cat.shape, new_columns))\n","\n","# Step 2: Append the numerical columns\n","X = numpy.hstack([X_cat, melb_df[numerical_cols].values])\n","new_columns.extend(numerical_cols)\n","print(\"Matrix has shape {}, with columns: {}\".format(X_cat.shape, new_columns))\n","\n","# Step 3: Append some new features, like PCA\n","pca = PCA(n_components=2)\n","pca_dummy_features = pca.fit_transform(X)\n","X_pca = numpy.hstack([X, pca_dummy_features])\n","new_columns.extend(['pca1', 'pca2'])\n","\n","## Re-build dataframe\n","processed_melb_df = pandas.DataFrame(data=X_pca, columns=new_columns)\n","processed_melb_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","# Ejercicio 5 - Documentación"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mVBLFc8PhRtW"},"source":["En un documento `.pdf` o `.md` realizar un reporte de las operaciones que realizaron para obtener el conjunto de datos final. Se debe incluir:\n","  1. Criterios de exclusión (o inclusión) de filas\n","  2. Interpretación de las columnas presentes\n","  2. Todas las transofrmaciones realizadas\n","\n","Este documento es de uso técnico exclusivamente, y su objetivo es permitir que otres desarrolladores puedan reproducir los mismos pasos y obtener el mismo resultado. Debe ser detallado pero consiso. Por ejemplo:\n","\n","```\n","  ## Criterios de exclusión de ejemplos\n","  1. Se eliminan ejemplos donde el año de construcción es previo a 1900\n","\n","  ## Características seleccionadas\n","  ### Características categóricas\n","  1. Type: tipo de propiedad. 3 valores posibles\n","  2. ...\n","  Todas las características categóricas fueron codificadas con un\n","  método OneHotEncoding utilizando como máximo sus 30 valores más \n","  frecuentes.\n","  \n","  ### Características numéricas\n","  1. Rooms: Cantidad de habitaciones\n","  2. Distance: Distancia al centro de la ciudad.\n","  3. airbnb_mean_price: Se agrega el precio promedio diario de \n","     publicaciones de la plataforma AirBnB en el mismo código \n","     postal. [Link al repositorio con datos externos].\n","\n","  ### Transformaciones:\n","  1. Todas las características numéricas fueron estandarizadas.\n","  2. La columna `Suburb` fue imputada utilizando el método ...\n","  3. Las columnas `YearBuilt` y ... fueron imputadas utilizando el \n","     algoritmo ...\n","  4. ...\n","\n","  ### Datos aumentados\n","  1. Se agregan las 5 primeras columnas obtenidas a través del\n","     método de PCA, aplicado sobre el conjunto de datos\n","     totalmente procesado.\n","```\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
