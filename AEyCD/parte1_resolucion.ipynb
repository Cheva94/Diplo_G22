{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LYvAOR2VzHmW"
   },
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio y curación de datos\n",
    "\n",
    "### Trabajo práctico entregable - Grupo 22 - Parte 1\n",
    "\n",
    "**Integrantes:**\n",
    "- Chevallier-Boutell, Ignacio José\n",
    "- Ribetto, Federico Daniel\n",
    "- Rosa, Santiago\n",
    "- Spano, Marcelo\n",
    "\n",
    "**Seguimiento:** Meinardi, Vanesa\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1680803577547,
     "user": {
      "displayName": "Laura Minuet",
      "userId": "00787725849952937741"
     },
     "user_tz": 180
    },
    "id": "Xwdfo7z20TUK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XY2Hl-Ma07Nn"
   },
   "source": [
    "## Acerca de los datasets\n",
    "\n",
    "El dataset a utilizar proviene de la [compentencia Kaggle](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot) sobre estimación de precios de ventas de propiedades en Melbourne, Australia. Particularmente, utilizaremos el conjunto de datos reducido producido por [DanB](https://www.kaggle.com/dansbecker). Este [dataset](https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/melb_data.csv) está disponible en internet, desde donde lo usaremos.\n",
    "\n",
    "Por otro lado, vamos a aumentar los datos presentes en dicho conjunto utilizando un dataset similar: las publicaciones de la plataforma AirBnB en Melbourne en el año 2018. El objetivo es estimar con mayor precisión el valor del vecindario de cada propiedad. Este otro [dataset](https://www.kaggle.com/tylerx/melbourne-airbnb-open-data?select=cleansed_listings_dec18.csv), también disponible en internet, es un conjunto de datos de *scrapings* del sitio realizado por [Tyler Xie](https://www.kaggle.com/tylerx), también disponible en una competencia de Kaggle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 1 - SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Conexión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ejecutar consultas simples en SQL con SQLAlchemy, primero debemos crear un ***engine*** : es el punto de partida para cualquier aplicación que hagamos de SQLAlchemy, proporcionando una forma de conectarse e interactuar con la base de datos. El mismo provee además:\n",
    "- Una ***connection pool***: conjunto de conexiones a la base de datos que permanecen activas por largos períodos de tiempo y se pueden reutilizar eficientemente, previniendo el *overhead* que deviene de la creación de nuevas conexiones, y aumentando la velocidad de funcionamiento.\n",
    "- Un **dialecto**: SQLAlchemy puede trabajar con muchos tipos de bases de datos, siendo cada uno de estos tipos un dialecto diferente (MySQL, PostgreSQL, Oracle, SQLite, etcétera).\n",
    "\n",
    "En nuestro caso el dialecto será SQLite y la ingesta de datos se hará en la base de datos database.sqlite3, por lo que instanciamos el *engine* de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo flag logs the SQL queries executed by the engine. It’s helpful for\n",
    "# debugging purposes (True), but don’t use it in a production environmen (False)\n",
    "engine = create_engine('sqlite:///database.sqlite3', echo=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ingesta de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos de la competencia Kaggle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos de la competencia Kaggle utilizando pandas. Vemos que en total consta de 13.580 registros con respuestas a 21 variables diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del csv\n",
    "url_kag = 'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/melb_data.csv'\n",
    "melb_df = pd.read_csv(url_kag)\n",
    "total_ans_kag = len(melb_df)\n",
    "print(f'Cantidad de respuestas en el dataset de Kaggle: {total_ans_kag}')\n",
    "display(melb_df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Información disponible en el dataset de Kaggle ---')\n",
    "keys_kag = melb_df.keys()\n",
    "print(f'Contiene un total de {len(keys_kag)} columnas:')\n",
    "for k in range(len(keys_kag)):\n",
    "    print(f'{k+1}) {keys_kag[k]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos de Airbnb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos de Airbnb utilizando pandas. Vemos que en total consta de 22.895 registros con respuestas a 84 variables diferentes, *i.e.* tiene 9.315 registros más que en el dataset de Kaggle y responde a 63 variables más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del csv\n",
    "url_air = 'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/cleansed_listings_dec18.csv'\n",
    "airbnb_df = pd.read_csv(url_air)\n",
    "total_ans_air = len(airbnb_df)\n",
    "print(f'Cantidad de respuestas en el dataset de Airbnb: {total_ans_air}')\n",
    "display(airbnb_df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Información disponible en el dataset de Airbnb ---')\n",
    "keys_air = airbnb_df.keys()\n",
    "print(f'Contiene un total de {len(keys_air)} columnas:')\n",
    "for k in range(len(keys_air)):\n",
    "    print(f'{k+1}) {keys_air[k]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a reducir el dataframe y quedarnos sólo con aquellas columnas que consideramos relevantes para el análisis que pretendemos hacer. Coincide que son 21 variables, pero no necesariamente la relación es 1:1 con las variables de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols_air = [\n",
    "    'host_location', 'host_neighborhood', 'street', 'neighborhood', 'city',\n",
    "    'suburb', 'state', 'zipcode', 'latitude', 'longitude', 'is_location_exact',\n",
    "    'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms',\n",
    "    'beds', 'bed_type', 'price', 'weekly_price', 'monthly_price'\n",
    "]\n",
    "\n",
    "airbnb_df = airbnb_df[int_cols_air]\n",
    "display(airbnb_df[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de códigos postales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos combinar los datos de Airbnb con los datos de Kaggle. Para ello utilizaremos el código postal como clave común: 'Postcode' en melb_df y 'zipcode' en airbnb_df. Antes que anda, debemos asegurarnos que las columnas se encuentren limpias y con un formato común."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por un lado, vemos que 'Postcode' en melb_df tiene un formato común: son todos float con un 1 decimal. Vamos a pasarlos todos a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Formato original de los datos:')\n",
    "display(melb_df['Postcode'].value_counts().iloc[:10])\n",
    "print('---------------------------------------------------------------------\\n')\n",
    "melb_df['postcode_int'] = melb_df['Postcode'].fillna(0).astype('int')\n",
    "print('Datos pasados a enteros:')\n",
    "display(melb_df['postcode_int'].value_counts().iloc[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte , vemos que 'zipcode' en airbnb_df tiene uan mezcla de formatos: algunos son float con un 1 decimal y otros son enteros. Vamos a pasarlos todos a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Formato original de los datos:')\n",
    "display(airbnb_df['zipcode'].value_counts()[:10])\n",
    "print('---------------------------------------------------------------------\\n')\n",
    "# Se estandariza el tipo de datos para la columna zipcode\n",
    "airbnb_df['zipcode'] = pd.to_numeric(airbnb_df.zipcode, errors='coerce')\n",
    "airbnb_df['zipcode_int'] = airbnb_df['zipcode'].fillna(0).astype('int')\n",
    "print('Datos pasados a enteros:')\n",
    "display(airbnb_df['zipcode_int'].value_counts()[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribimos todos los registros de melb_df a la tabla \"Kaggle\" de la base de datos SQL creada previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.to_sql('kaggle', con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribimos todos los registros de airbnb_df a la tabla \"airbnb\" de la base de datos SQL creada previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.to_sql('airbnb', con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Consultas\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    Consigna >>>>\n",
    "</span>\n",
    "\n",
    "Implementar consultas en SQL que respondan con la siguiente información:\n",
    "\n",
    "- cantidad de registros totales por ciudad.\n",
    "- cantidad de registros totales por barrio y ciudad.\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    <<<< Consigna\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cantidad de registros por ciudad:\n",
    "query_c = \"SELECT price FROM survey2 GROUP BY city\"\n",
    "#solo por ciudad y barrio:\n",
    "query_cb = \"SELECT price FROM survey2 GROUP BY city and neighborhood\"\n",
    "\n",
    "con = engine.connect()\n",
    "sql_text = text(query_cb)\n",
    "result = con.execute(sql_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función para ejecutar queries con la conexión creada previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "  with engine.connect() as con:\n",
    "    rs = con.execute(text(query))\n",
    "    df_rs = pd.DataFrame(rs.fetchall())\n",
    "  return df_rs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la cantidad de registros totales por ciudad agrupando por la columna CITY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_city = \"\"\"SELECT CITY AS CIUDAD, COUNT(*) AS CANT_REGISTROS \n",
    "                FROM AIRBNB\n",
    "                GROUP BY CITY\"\"\"\n",
    "df_city = execute_query(query_city)\n",
    "df_city.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la cantidad de registros totales por barrio y ciudad agrupando por las columnas NEIGHBORHOOD y CITY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_neighborhood_city = \"\"\"SELECT NEIGHBORHOOD AS BARRIO, CITY AS CIUDAD, COUNT(*) AS CANT_REGISTROS \n",
    "                              FROM AIRBNB\n",
    "                              GROUP BY NEIGHBORHOOD, CITY\"\"\"\n",
    "df_neighborhood_city = execute_query(query_neighborhood_city)\n",
    "df_neighborhood_city.tail(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combinación\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    Consigna >>>>\n",
    "</span>\n",
    "\n",
    "Combinar los datasets de ambas tablas ingestadas utilizando el comando JOIN de SQL  para obtener un resultado similar a lo realizado con Pandas en clase.\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    <<<< Consigna\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza una subquery en la que se define AIRBNB_AGG con las agregaciones generadas en clase con Pandas.\n",
    "# AIRBNB_AGG es joineada con la tabla original PROP_MELB\n",
    "query_join = \"\"\"WITH AIRBNB_AGG AS (\n",
    "                  SELECT ZIPCODE, \n",
    "                    AVG(PRICE) AS AIRBNB_PRICE_MEAN,\n",
    "                    COUNT(PRICE) AS AIRBNB_RECORD_COUNT,\n",
    "                    AVG(WEEKLY_PRICE) AS AIRBNB_WEEKLY_PRICE_MEAN,\n",
    "                    AVG(MONTHLY_PRICE) AS AIRBNB_MONTHLY_PRICE_MEAN\n",
    "                  FROM AIRBNB\n",
    "                  GROUP BY ZIPCODE\n",
    "                )\n",
    "                SELECT * FROM PROP_MELB A\n",
    "                LEFT JOIN AIRBNB_AGG B \n",
    "                ON A.Postcode = B.zipcode\"\"\"\n",
    "df_join = execute_query(query_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 2 - Pandas\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    Consigna >>>>\n",
    "</span>\n",
    "\n",
    "Pueden leer otras columnas del conjunto de AirBnB además de las que están en `interesting_cols`, si les parecen relevantes.\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    <<<< Consigna\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    Consigna >>>>\n",
    "</span>\n",
    "\n",
    "Seleccionar un subconjunto de columnas que les parezcan relevantes al problema de predicción del valor de la propiedad. Justificar las columnas seleccionadas y las que no lo fueron.\n",
    " - Eliminar los valores extremos que no sean relevantes para la predicción de valores de las propiedades.\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    <<<< Consigna\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el dataset nuevamente con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/melb_data.csv')\n",
    "df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos las columnas categóricas de las numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "num_cols = ['Rooms', 'Price', 'Distance', 'Bedroom2', 'Bathroom',\n",
    "       'Car', 'Landsize', 'BuildingArea', 'YearBuilt',\n",
    "       'Lattitude', 'Longtitude', 'Propertycount']\n",
    "cat_cols = [x for x in cols if x not in num_cols and x != 'index']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de variables numéricas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la correlación de las variables numéricas con el precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].corr()['Price']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un scatterplot del Precio en función de todas las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "  plt.figure(figsize=(8,3))\n",
    "  plt.scatter(df[col], df['Price'])\n",
    "  plt.axvline(df[col].mode()[0], color='r')\n",
    "  plt.grid()\n",
    "  plt.title(col)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers:\n",
    "- En la variable Bedroom2 vemos que tiene un valor extremo = 20.\n",
    "- En la variable Landsize vemos que tiene un valor extremo > 400000\n",
    "- En la variable BuildingArea vemos que tiene un valor extremo > 40000\n",
    "- En la variable YearBuilt vemos que tiene un valor extremo en 1200\n",
    "\n",
    "Quitamos estos valores extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Bedroom2'] < 20]\n",
    "df = df[df['Landsize'] < 400000]\n",
    "df = df[df['BuildingArea'] < 40000]\n",
    "df = df[df['YearBuilt'] > 1200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos nuevamente la correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_join[num_cols].corr()['Price']\n",
    "corr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos boxplots para las variables discretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_cols = ['Rooms', 'Bedroom2', 'Bathroom', 'Car']\n",
    "for col in discrete_cols:\n",
    "  df_var = df[[col, 'Price']]\n",
    "  df_var['count'] = df_var[col].astype(str)\n",
    "  plt.figure(figsize=(8,3))\n",
    "  sns.boxplot(data=df_var, x='Price', y='count')\n",
    "  plt.title(col)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos a las variables continuas en 6 cuantiles y realizamos los boxplots del Precio.\n",
    "\n",
    "Se eligen 6 ya que para más cuantiles el código da el siguiente error:\n",
    "\n",
    "\"ValueError: Bin labels must be one fewer than the number of bin edges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = [x for x in num_cols if x not in discrete_cols and x!='Price']\n",
    "for col in continuous_cols:\n",
    "  df_var = df[[col, 'Price']]\n",
    "  df_var['quantile'] = pd.qcut(df_var[col], 6, labels=['1','2','3','4','5','6'])\n",
    "  plt.figure(figsize=(8,3))\n",
    "  sns.boxplot(data=df_var, x='Price', y='quantile')\n",
    "  plt.title(col)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo la correlación y los gráficos anteriores tomamos deciciones respecto a cada columna:\n",
    "\n",
    "\n",
    "*   Rooms: La correlación con el Precio es de 0.52 por lo que consideramos que es importante para la predicción del valor de la propiedad.\n",
    "*   Bedroom2: La correlación con el Precio es de 0.5 por lo que consideramos que es importante para la predicción del valor de la propiedad.\n",
    "*   Bathroom: La correlación con el Precio es de 0.49 por lo que consideramos que es importante para la predicción del valor de la propiedad.\n",
    "*   Car: La correlación Con el Precio es de 0.25. Viendo el scatterplot y el boxplot de la variable Car no se ve una relación clara con el Precio por lo que la descartamos.\n",
    "*   Distance: Si bien la correlación con el Precio es relativamente baja (-0.16), se puede observar que para valores en el scatterplot que para valores menores a 20, el precio alcanza los valores más altos mientras que para valores mayores a 20 el precio permanece acotado a valores pequeños. Por esta razón la consideramos en el dataset.\n",
    "*   Landsize: Se puede observar en el boxplot que las distribuciones son diferentes para cada cuantil, por lo que consideramos que es una variable importante para predecir el valor de la propiedad y la consideramos en el dataset.\n",
    "*   BuildingArea: Sucede lo mismo que en la variable Landsize, además que posee una correlación alta con el Precio, por lo que la consideramos en el dataset. \n",
    "*   YearBuilt: En el boxplot se puede observar que para cuantiles más bajos (1 y 2) el Precio alcanza valores mayores que para el resto de los cuantiles. Además la correlación es negativa, lo que tiene sentido suponiendo que, cuando más vieja es la propiedad, esta pierde valor. La consideramos en el dataset.\n",
    "*   Lattitude: En el boxplot se puede observar que para cuantiles intermedios (2 y 3) el Precio alcanza valores mayores que para el resto de los cuantiles. La consideramos en el dataset.\n",
    "*   Longitude: En el boxplot se puede observar que para cuantiles intermedios (4 y 5) el Precio alcanza valores mayores que para el resto de los cuantiles. La consideramos en el dataset.\n",
    "*   Propertycount: La correlación Con el Precio es de -0.05. Viendo el scatterplot y el boxplot de la variable Propertycount no se ve una relación clara con el Precio por lo que la descartamos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_num_cols = ['Rooms', 'Bedroom2', 'Bathroom', 'Distance', 'Landsize',\n",
    "                    'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la cardinalidad de cada una y el porcentaje de repeticiones que tienen las 10 categorías con mayor cantidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "  print(col)\n",
    "  print('Cardinalidad:', df[col].nunique())\n",
    "  print(100*df[col].value_counts(normalize=True).iloc[:10])\n",
    "  print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suburb: Tiene 300 valores diferentes y la categoría que posee la mayor cantidad de casos solo tiene el 2,5% por lo que la descartamos.\n",
    "* Address: La descartamos ya que la dirección es única para cada propiedad y no es representativa.\n",
    "* Type: Tiene 3 valores únicos, la consideramos en el dataset.\n",
    "* Method: Posee 5 valores únicos, la consideramos en el dataset.\n",
    "* SellerG: Posee 214 valores únicos, pero vemos que algunos de estos valores poseen un gran porcentaje, como Nelson que tiene el 12% o Jellis con el 10%. La consideramos en el dataset.\n",
    "* Date: No consieramos que sea relevante, la descartamos.\n",
    "* Postcode: Tiene 190 valores diferentes y la categoría que posee la mayor cantidad de casos solo tiene el 2,5% por lo que la descartamos.\n",
    "* CouncilArea: Posee 31 valores únicos, pero vemos que algunos de estos valores poseen un gran porcentaje de casos, como Moreland que tiene el 10% o Boroondara con el 9%. La consideramos en el dataset.\n",
    "* Regionname: Tiene 8 valores únicos, la consideramos en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselected_cat_cols = ['Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las variables de mayor cardinalidad, CouncilArea y SellerG, creamos una categoría nueva \"Other\" para agrupar a los valores que posean menos del 1% de los casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['SellerG', 'CouncilArea']:\n",
    "  value_counts = 100*df[col].value_counts(normalize=True)\n",
    "  lower_values = value_counts[value_counts<1].index.tolist()\n",
    "  df[col] = df[col].apply(lambda x: 'Other' if x in lower_values else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la nueva cardinalidad de ambas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SellerG'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CouncilArea'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos los boxplots para las variables categóricas preseleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in preselected_cat_cols:\n",
    "  values = df[col].value_counts(normalize=True).index[:10].tolist()\n",
    "  plt.figure(figsize=(8,4))\n",
    "  sns.boxplot(data=df[df[col].isin(values)], y=col, x='Price')\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En todos los casos vemos que hay valores para los cuales el precio tiende a tener precios mayores que en otros por lo que seleccionamos todas estas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cat_cols = preselected_cat_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unificamos variables seleccionadas numéricas y categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = selected_num_cols + selected_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[selected_cols + ['Price', 'Postcode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    Consigna >>>>\n",
    "</span>\n",
    "\n",
    "Agregar información adicional respectiva al entorno de una propiedad a partir del [conjunto de datos de AirBnB](https://www.kaggle.com/tylerx/melbourne-airbnb-open-data?select=cleansed_listings_dec18.csv) utilizado en el práctico. \n",
    "  1. Seleccionar qué variables agregar y qué combinaciones aplicar a cada una. Por ejemplo, pueden utilizar solo la columna `price`, o aplicar múltiples transformaciones como la mediana o el mínimo.\n",
    "  1. Utilizar la variable zipcode para unir los conjuntos de datos. Sólo incluir los zipcodes que tengan una cantidad mínima de registros (a elección) como para que la información agregada sea relevante.\n",
    "  2. Investigar al menos otras 2 variables que puedan servir para combinar los datos, y justificar si serían adecuadas o no. Pueden asumir que cuentan con la ayuda de anotadores expertos para encontrar equivalencias entre barrios o direcciones, o que cuentan con algoritmos para encontrar las n ubicaciones más cercanas a una propiedad a partir de sus coordenadas geográficas. **NO** es necesario que realicen la implementación.\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    <<<< Consigna\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df = pd.read_csv(\n",
    "    'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/cleansed_listings_dec18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estandariza el tipo de datos para la columna zipcode\n",
    "airbnb_df['zipcode'] = pd.to_numeric(airbnb_df.zipcode, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(airbnb_df.zipcode.value_counts().values)\n",
    "plt.axhline(100, color='g')\n",
    "plt.axhline(50, color='r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos los zipcodes que tengan una cantidad mayor o igual a 100 registros para que la información agregada sea relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = airbnb_df.zipcode.value_counts()\n",
    "value_counts = value_counts[value_counts>=100]\n",
    "airbnb_df = airbnb_df[airbnb_df['zipcode'].isin(value_counts.index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_price_by_zipcode = airbnb_df.groupby('zipcode')\\\n",
    "  .agg({'price': ['mean', 'count'], 'weekly_price': 'mean',\n",
    "        'monthly_price': 'mean', 'number_of_reviews': ['sum', 'mean'],\n",
    "        'review_scores_rating': ['min', 'max', 'mean']})\\\n",
    "  .reset_index()\n",
    "# Flatten the two level columns\n",
    "airbnb_price_by_zipcode.columns = [\n",
    "  ' '.join(col).strip()\n",
    "  for col in airbnb_price_by_zipcode.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_price_by_zipcode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "airbnb_price_by_zipcode = airbnb_price_by_zipcode.rename(\n",
    "    columns={'price mean': 'airbnb_price_mean',\n",
    "             'price count': 'airbnb_record_count',\n",
    "             'weekly_price mean': 'airbnb_weekly_price_mean',\n",
    "             'monthly_price mean': 'airbnb_monthly_price_mean',\n",
    "             'number_of_reviews sum': 'airbnb_number_of_reviews_sum', \n",
    "             'number_of_reviews mean': 'airbnb_number_of_reviews_mean', \n",
    "             'review_scores_rating min': 'airbnb_review_scores_rating_min', \n",
    "             'review_scores_rating max': 'airbnb_review_scores_rating_max',\n",
    "             'review_scores_rating mean': 'airbnb_review_scores_rating_mean'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_price_by_zipcode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.merge(\n",
    "    airbnb_price_by_zipcode, how='left',\n",
    "    left_on='Postcode', right_on='zipcode'\n",
    ")\n",
    "df_join.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se podría utilizar la variable Suburb que se encuentra en ambos datasets y posee una cardinalidad mayor al código postal en ambos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad Código postal:', melb_df.Postcode.nunique())\n",
    "print('Cardinalidad Suburbio:', melb_df.Suburb.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad Código postal:', airbnb_df.zipcode.nunique())\n",
    "print('Cardinalidad Suburbio:', airbnb_df.suburb.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción sería utilizar la latitud y longitud que se encuentra en ambos datasets y encontrar todas las propiedades que se encuentren a cierta distancia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 3 - Guardado final\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    Consigna >>>>\n",
    "</span>\n",
    "\n",
    "Crear y guardar un nuevo conjunto de datos con todas las transformaciones realizadas anteriormente.\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    <<<< Consigna\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el dataset en un archivo csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "path = '/content/drive/My Drive/new_dataset.csv'\n",
    "\n",
    "df_join.to_csv(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicios Opcionales\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    Consigna >>>>\n",
    "</span>\n",
    "\n",
    "1. Armar un script en python (archivo .py) [ETL](https://towardsdatascience.com/what-to-log-from-python-etl-pipelines-9e0cfe29950e) que corra los pasos de extraccion, transformacion y carga, armando una funcion para cada etapa del proceso y luego un main que corra todos los pasos requeridos.\n",
    "\n",
    "2. Armar un DAG en Apache Airflow que corra el ETL. (https://airflow.apache.org/docs/apache-airflow/stable/tutorial.html)\n",
    "\n",
    "<span style=\"color:green;font-size:18px\">\n",
    "    <<<< Consigna\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1NXWXyebR6mzAabyOPqghXpZQdyy05cRV",
     "timestamp": 1680785357097
    },
    {
     "file_id": "1OZLULlr-RkXwyhar7ED5fcXmPdgc6tGb",
     "timestamp": 1617224538047
    },
    {
     "file_id": "1xPL68eVaR0UF7XTcLU1rCMfpzuS7r6s0",
     "timestamp": 1617223947184
    },
    {
     "file_id": "1bChseZSrdGJSXfa-D2_lS0dx98wplQtD",
     "timestamp": 1614968149245
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
