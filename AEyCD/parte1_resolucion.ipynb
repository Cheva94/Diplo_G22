{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LYvAOR2VzHmW"
   },
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio y curación de datos\n",
    "\n",
    "### Trabajo práctico entregable - Grupo 22 - Parte 1\n",
    "\n",
    "**Integrantes:**\n",
    "- Chevallier-Boutell, Ignacio José\n",
    "- Ribetto, Federico Daniel\n",
    "- Rosa, Santiago\n",
    "- Spano, Marcelo\n",
    "\n",
    "**Seguimiento:** Meinardi, Vanesa\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1680803577547,
     "user": {
      "displayName": "Laura Minuet",
      "userId": "00787725849952937741"
     },
     "user_tz": 180
    },
    "id": "Xwdfo7z20TUK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XY2Hl-Ma07Nn"
   },
   "source": [
    "## Acerca de los datasets\n",
    "\n",
    "El dataset a utilizar proviene de la [compentencia Kaggle](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot) sobre estimación de precios de ventas de propiedades en Melbourne, Australia. Particularmente, utilizaremos el conjunto de datos reducido producido por [DanB](https://www.kaggle.com/dansbecker). Este [dataset](https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/melb_data.csv) está disponible en internet, desde donde lo usaremos.\n",
    "\n",
    "Por otro lado, vamos a aumentar los datos presentes en dicho conjunto utilizando un dataset similar: las publicaciones de la plataforma AirBnB en Melbourne en el año 2018. El objetivo es estimar con mayor precisión el valor del vecindario de cada propiedad. Este otro [dataset](https://www.kaggle.com/tylerx/melbourne-airbnb-open-data?select=cleansed_listings_dec18.csv), también disponible en internet, es un conjunto de datos de *scrapings* del sitio realizado por [Tyler Xie](https://www.kaggle.com/tylerx), también disponible en una competencia de Kaggle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 1 - SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Conexión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ejecutar consultas simples en SQL con SQLAlchemy, primero debemos crear un ***engine*** : es el punto de partida para cualquier aplicación que hagamos de SQLAlchemy, proporcionando una forma de conectarse e interactuar con la base de datos. El mismo provee además:\n",
    "- Una ***connection pool***: conjunto de conexiones a la base de datos que permanecen activas por largos períodos de tiempo y se pueden reutilizar eficientemente, previniendo el *overhead* que deviene de la creación de nuevas conexiones, y aumentando la velocidad de funcionamiento.\n",
    "- Un **dialecto**: SQLAlchemy puede trabajar con muchos tipos de bases de datos, siendo cada uno de estos tipos un dialecto diferente (MySQL, PostgreSQL, Oracle, SQLite, etcétera).\n",
    "\n",
    "En nuestro caso el dialecto será SQLite y la ingesta de datos se hará en la base de datos database.sqlite3, por lo que instanciamos el *engine* de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo flag logs the SQL queries executed by the engine. It’s helpful for\n",
    "# debugging purposes (True), but don’t use it in a production environmen (False)\n",
    "engine = create_engine('sqlite:///database.sqlite3', echo=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ingesta de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos de la competencia Kaggle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos de la competencia Kaggle utilizando pandas. Vemos que en total consta de 13.580 registros con respuestas a 21 variables diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del csv\n",
    "url_kag = 'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/melb_data.csv'\n",
    "melb_df = pd.read_csv(url_kag)\n",
    "total_ans_kag = len(melb_df)\n",
    "print(f'Cantidad de respuestas en el dataset de Kaggle: {total_ans_kag}')\n",
    "display(melb_df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Información disponible en el dataset de Kaggle ---')\n",
    "keys_kag = melb_df.keys()\n",
    "print(f'Contiene un total de {len(keys_kag)} columnas:')\n",
    "for k in range(len(keys_kag)):\n",
    "    print(f'{k+1}) {keys_kag[k]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos de Airbnb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos de Airbnb utilizando pandas. Vemos que en total consta de 22.895 registros con respuestas a 84 variables diferentes, *i.e.* tiene 9.315 registros más que en el dataset de Kaggle y responde a 63 variables más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del csv\n",
    "url_air = 'https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/cleansed_listings_dec18.csv'\n",
    "airbnb_df = pd.read_csv(url_air)\n",
    "total_ans_air = len(airbnb_df)\n",
    "print(f'Cantidad de respuestas en el dataset de Airbnb: {total_ans_air}')\n",
    "display(airbnb_df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Información disponible en el dataset de Airbnb ---')\n",
    "keys_air = airbnb_df.keys()\n",
    "print(f'Contiene un total de {len(keys_air)} columnas:')\n",
    "for k in range(len(keys_air)):\n",
    "    print(f'{k+1}) {keys_air[k]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a reducir el dataframe y quedarnos sólo con aquellas columnas que consideramos relevantes para el análisis que pretendemos hacer. Coincide que son 21 variables, pero no necesariamente la relación es 1:1 con las variables de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols_air = [\n",
    "    'host_location', 'host_neighborhood', 'street', 'neighborhood', 'city',\n",
    "    'suburb', 'state', 'zipcode', 'latitude', 'longitude', 'is_location_exact',\n",
    "    'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms',\n",
    "    'beds', 'bed_type', 'price', 'weekly_price', 'monthly_price'\n",
    "]\n",
    "\n",
    "airbnb_df = airbnb_df[int_cols_air]\n",
    "display(airbnb_df[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de códigos postales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos combinar los datos de Airbnb con los datos de Kaggle. Para ello utilizaremos el código postal como clave común: 'Postcode' en melb_df y 'zipcode' en airbnb_df. Antes que anda, debemos asegurarnos que las columnas se encuentren limpias y con un formato común."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por un lado, vemos que 'Postcode' en melb_df tiene un formato común: son todos float con un 1 decimal. Vamos a pasarlos todos a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Formato original de los datos:')\n",
    "display(melb_df['Postcode'].value_counts().iloc[:10])\n",
    "print('---------------------------------------------------------------------\\n')\n",
    "melb_df['postcode_int'] = melb_df['Postcode'].fillna(0).astype('int')\n",
    "print('Datos pasados a enteros:')\n",
    "display(melb_df['postcode_int'].value_counts().iloc[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte , vemos que 'zipcode' en airbnb_df tiene uan mezcla de formatos: algunos son float con un 1 decimal y otros son enteros. Vamos a pasarlos todos a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Formato original de los datos:')\n",
    "display(airbnb_df['zipcode'].value_counts()[:10])\n",
    "print('---------------------------------------------------------------------\\n')\n",
    "# Se estandariza el tipo de datos para la columna zipcode\n",
    "airbnb_df['zipcode'] = pd.to_numeric(airbnb_df.zipcode, errors='coerce')\n",
    "airbnb_df['zipcode_int'] = airbnb_df['zipcode'].fillna(0).astype('int')\n",
    "print('Datos pasados a enteros:')\n",
    "display(airbnb_df['zipcode_int'].value_counts()[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribimos todos los registros de melb_df a la tabla \"Kaggle\" de la base de datos SQL creada previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.to_sql('kaggle', con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribimos todos los registros de airbnb_df a la tabla \"airbnb\" de la base de datos SQL creada previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.to_sql('airbnb', con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Consultas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de ejecutar consultas SQL, no debemos hacerlo directamente con el *engine*, sino que debemos hacerlo a través de instancia de conexión, la cual se crea con `engine.connect()`, apartádose momentáneamente del *connection pool*. \n",
    "\n",
    "En términos de desempeño, es muy importante cerrar las conexiones luego de utilizarlas. Al cerrar la conexión (`.close()`), la conexión se recicla y vuelve al *pool* para ser reutilizada, lo cual previene el overhead de creación. Una alternativa al cierre de la conexión para su reciclaje es utilizar un bloque `with()`: la conexión se cerrará automáticamente luego de que se ejecute el bloque de código dentro del `with()`.\n",
    "\n",
    "Otra cosa a tener en cuenta es que alimentar la ejecución con una *string* pelada está deprecado, debiendo usar en su lugar la función `text()` dentro de sqlalchemy para proveer la consulta SQL.\n",
    "\n",
    "Considerando todo lo dicho, definimos una función para facilitar la ejecución de consultas.\n",
    "\n",
    "**Observación:** la consigna pide distinguir por ciudad y por ciudad+barrio. Estos datos sólo están disponibles en la base de datos de Airbnb, así que las consultas se realizarán sobre la tabla correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "  with engine.connect() as con:\n",
    "    rs = con.execute(text(query))\n",
    "    df_rs = pd.DataFrame(rs.fetchall())\n",
    "  return df_rs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de registros totales por ciudad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la cantidad de registros totales por ciudad, agrupando por la columna *city*. Ordenamos además de mayor a menor cantidad de registros. Tenemos que Melbourne va a la cabeza con 7368, seguido por Port Phillip con 2808."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_city = \"\"\"SELECT city AS Ciudad, COUNT(*) AS Registros\n",
    "                FROM airbnb\n",
    "                GROUP BY city\n",
    "                ORDER BY Registros DESC\"\"\"\n",
    "df_city = execute_query(query_city)\n",
    "df_city.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de registros totales por barrio y ciudad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora la cantidad de registros totales por barrio y por ciudad, agrupando por las columnas *neighborhood* y *city*. Ordenamos además de mayor a menor cantidad de registros. Al considerar los barrios, tenemos que Melbourne sigue encabezando la lista, siendo Central Business District y Southbank los dos mayoritarios, con 3726 y 1204 registros, respectivamente\n",
    "\n",
    "va a la cabeza con 7368, seguido por Port Phillip con 2808."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_neighborhood_city = \"\"\"SELECT neighborhood AS Barrio, city AS Ciudad, COUNT(*) AS Registros\n",
    "                FROM airbnb\n",
    "                GROUP BY neighborhood, city\n",
    "                ORDER BY Registros DESC\"\"\"\n",
    "df_neighborhood_city = execute_query(query_neighborhood_city)\n",
    "df_neighborhood_city.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Combinación de tablas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que nuestro objetivo es combinar ambas tablas, ampliando así la información disponible en el dataset de Kaggle sobre el valor del vecindario de la propiedad con información proveniente del dataset de AirBnB, utilizaremos de esta última tabla lo siguientes promedios asociados al código postal:\n",
    "* Promedio del precio diario (`price`).\n",
    "* Promedio del precio semanal (`weekly_price`).\n",
    "* Promedio del precio mensual (`monthly_price`).\n",
    "\n",
    "Consideremos además el conteo de cuántos registros responden a cada uno de estos promedios, para así tener una manera de ponderar la relevancia que nos aporta cada uno de estos datos a la hora de extraer conclusiones.\n",
    "\n",
    "Para lograr esto usando el comando `JOIN` de SQL, ejecutamos una subconsulta, donde se define una tabla `airbnb_agg` con todas las agregaciones deseadas. Finalmente, esta nueva tabla es combinada con la tabla de Kaggle considerando los códigos postales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_join = \"\"\"WITH airbnb_agg AS (\n",
    "                  SELECT zipcode_int, \n",
    "                    AVG(price) AS airbnb_daily_mean,\n",
    "                    COUNT(price) AS airbnb_daily_count,\n",
    "                    AVG(weekly_price) AS airbnb_weekly_mean,\n",
    "                    COUNT(weekly_price) AS airbnb_weekly_count,\n",
    "                    AVG(monthly_price) AS airbnb_monthly_mean,\n",
    "                    COUNT(monthly_price) AS airbnb_monthly_count\n",
    "                  FROM airbnb\n",
    "                  GROUP BY zipcode_int\n",
    "                )\n",
    "                SELECT * FROM Kaggle A\n",
    "                LEFT JOIN airbnb_agg B \n",
    "                ON A.Postcode_int = B.zipcode_int\"\"\"\n",
    "df_join = execute_query(query_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 2 - Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Selección de columnas relevantes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retomamos el dataset de Kaggle ya cargado con pandas (`melb_d`) y generamos uno nuevo (`df`) donde nos quedamos con la columna de código postal ya procesada. El objetivo final es filtrar las columnas, seleccionando aquellas que consideramos relevantes para una buena predicción del valor de la propiedad.\n",
    "\n",
    "Comenzaremos nuestro análisis separando las 21 columnas entre categóricas y numéricas. De las 13 variables numéricas, 5 hace referencia a la ubicación geográfica (Distance, Lattitude, Longtitude, Propertycount y Postcode) mientras que las otras 8 son características de la vivienda (Rooms, Price,  Bedroom2, Bathroom, Car, Landsize, BuildingArea y YearBuilt). Por otro lado, entre las 8 categóricas tenemos 4 que hacen referencia a la ubicación geográfica (Suburb, Address, CouncilArea y Regionname) y 4 que caracterizan de alguna manera la vivienda (Method, SellerG, Date y Type). Tendremos esto en cuenta a la hora de encarar los diferentes análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removemos la columna 'Postcode' ya que tenemos la columna editada 'postcode_int'\n",
    "df = melb_df.copy()\n",
    "df = df.drop(['Postcode'], axis=1)\n",
    "df.rename(columns = {'postcode_int': 'Postcode'}, inplace = True)\n",
    "\n",
    "num_geo = ['Distance', 'Propertycount',\n",
    "            'Lattitude', 'Longtitude']\n",
    "num_home = ['YearBuilt', 'Landsize', 'BuildingArea', 'Price',\n",
    "            'Rooms', 'Bedroom2', 'Bathroom', 'Car']\n",
    "\n",
    "cat_geo = ['Suburb', 'Address', 'CouncilArea', 'Regionname', 'Postcode']\n",
    "cat_home = ['Method', 'SellerG', 'Date', 'Type']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de variables numéricas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado de variables numéricas geográficas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando conjuntamente la estadística descriptiva junto a los histogramas, vemos que:\n",
    "* Tanto longitud y latitud están bastante simétricamente distribuidas.\n",
    "* Las otras 3 variables son asimétricas hacia la derecha.\n",
    "\n",
    "En el caso de Propertycount se observa un valor extremo mayor a 20.000, sin embargo este valor posee una cantidad importante de cuentas (aproximadamente un tercio del máximo) por lo que no lo descartamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_geo].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(12, 10))    \n",
    "\n",
    "sns.histplot(df[num_geo[0]], ax=axs[0, 0], color='tab:orange')\n",
    "\n",
    "sns.histplot(df[num_geo[1]], ax=axs[0, 1], color='tab:orange')\n",
    "\n",
    "sns.histplot(df[num_geo[2]], ax=axs[1, 0], color='tab:orange')\n",
    "\n",
    "sns.histplot(df[num_geo[3]], ax=axs[1, 1], color='tab:orange')\n",
    "\n",
    "axs[0, 0].set_ylabel(\"\")\n",
    "axs[0, 1].set_ylabel(\"\")\n",
    "axs[1, 0].set_ylabel(\"\")\n",
    "axs[1, 1].set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado de variables numéricas que caracterizan a la vivienda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando conjuntamente la estadística descriptiva junto a los histogramas, vemos que todas las distribuciones son asimétricas. Particularmente:\n",
    "* YearBuilt tiene cola hacia la izquierda.\n",
    "* Las demás tienen cola hacia la derecha.\n",
    "\n",
    "Considerando las colas, en principio creemos necesario cortar:\n",
    "* Bedroom2 menor a 20\n",
    "* Landsize menor a 3000\n",
    "* BuildingArea menor a 1500\n",
    "* YearBuilt mayor a 1200\n",
    "* Price menor a 6000000\n",
    "\n",
    "De esta forma eliminamos los valores extremos que se observa en cada uno de las variables numéricas que caracterizan a la vivienda.\n",
    "\n",
    "En el proceso se eliminaron 147 registros. Con esto se ha quitado el 1.08% del total de registros originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_home].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize=(24, 10))    \n",
    "\n",
    "sns.histplot(df[num_home[0]], ax=axs[0, 0], color='tab:orange')\n",
    "sns.histplot(df[num_home[1]], ax=axs[0, 1], color='tab:orange')\n",
    "sns.histplot(df[num_home[2]], ax=axs[1, 0], color='tab:orange')\n",
    "sns.histplot(df[num_home[3]], ax=axs[1, 1], color='tab:orange')\n",
    "sns.histplot(df[num_home[4]], ax=axs[0, 2], color='tab:orange')\n",
    "sns.histplot(df[num_home[5]], ax=axs[0, 3], color='tab:orange')\n",
    "sns.histplot(df[num_home[6]], ax=axs[1, 2], color='tab:orange')\n",
    "sns.histplot(df[num_home[7]], ax=axs[1, 3], color='tab:orange')\n",
    "\n",
    "axs[0, 0].set_ylabel(\"\")\n",
    "axs[0, 1].set_ylabel(\"\")\n",
    "axs[1, 0].set_ylabel(\"\")\n",
    "axs[1, 1].set_ylabel(\"\")\n",
    "axs[0, 2].set_ylabel(\"\")\n",
    "axs[0, 3].set_ylabel(\"\")\n",
    "axs[1, 2].set_ylabel(\"\")\n",
    "axs[1, 3].set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En todos los casos se conservan los nulos para luego ser imputados\n",
    "df_filtered = df.copy()\n",
    "df_filtered = df_filtered[(df_filtered['Bedroom2'] < 20) | (df_filtered['Bedroom2'].isnull())]\n",
    "df_filtered = df_filtered[(df_filtered['Landsize'] < 3000) | (df_filtered['Landsize'].isnull())]\n",
    "df_filtered = df_filtered[(df_filtered['BuildingArea'] < 1500)  | (df_filtered['BuildingArea'].isnull())]\n",
    "df_filtered = df_filtered[(df_filtered['YearBuilt'] > 1200) | (df_filtered['YearBuilt'].isnull())]\n",
    "df_filtered = df_filtered[(df_filtered['Price'] < 6000000) | (df_filtered['Price'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize=(24, 10))    \n",
    "\n",
    "sns.histplot(df_filtered[num_home[0]], ax=axs[0, 0], color='tab:orange')\n",
    "sns.histplot(df_filtered[num_home[1]], ax=axs[0, 1], color='tab:orange')\n",
    "sns.histplot(df_filtered[num_home[2]], ax=axs[1, 0], color='tab:orange')\n",
    "sns.histplot(df_filtered[num_home[3]], ax=axs[1, 1], color='tab:orange')\n",
    "sns.histplot(df_filtered[num_home[4]], ax=axs[0, 2], color='tab:orange')\n",
    "sns.histplot(df_filtered[num_home[5]], ax=axs[0, 3], color='tab:orange')\n",
    "sns.histplot(df_filtered[num_home[6]], ax=axs[1, 2], color='tab:orange')\n",
    "sns.histplot(df_filtered[num_home[7]], ax=axs[1, 3], color='tab:orange')\n",
    "\n",
    "axs[0, 0].set_ylabel(\"\")\n",
    "axs[0, 1].set_ylabel(\"\")\n",
    "axs[1, 0].set_ylabel(\"\")\n",
    "axs[1, 1].set_ylabel(\"\")\n",
    "axs[0, 2].set_ylabel(\"\")\n",
    "axs[0, 3].set_ylabel(\"\")\n",
    "axs[1, 2].set_ylabel(\"\")\n",
    "axs[1, 3].set_ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\tEliminamos {len(df) - len(df_filtered)} registros.')\n",
    "print(f'\\t{100*(len(df) - len(df_filtered))/len(df):.2f}% del total original.\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de correlación entre variables numéricas geográficas y el precio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinamos la correlación entre variables numéricas geográficas y el precio tanto analítica como gráficamente. A partir de esto, tomamos las siguientes decisiones:\n",
    "* Distance: si bien la correlación con el precio es baja (-0.17), se puede observar que a medida que la distancia al distrito comercial central crece, los precios disminuyen. Particularmente, los precios más bajos se encuentran a distancias mayores a 20. Por esta razón la consideramos en el dataset.\n",
    "* Propertycount: la correlación con el precio es de -0.04 y no hay una tendencia clara en las gráficas, por lo que la descartamos del dataset.\n",
    "* Lattitude y Longitude: en ambos casos la correlación con el precio es similar en intensidad (-0.22 y 0.20, respectivamente). Al considerar sus gráficas, hay una clara acumulación de puntos, definiendo una tendencia entre la ubiación geográfica y el precio, como era de esperar. Consideraremos ambas en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de coeficientes de correlación con el precio\n",
    "corr = df_filtered[num_geo+['Price']].corr()['Price']\n",
    "print(corr.drop('Price'))\n",
    "\n",
    "# Gráfica de correlaciones con el precio\n",
    "for col in num_geo:\n",
    "    sns.jointplot(data=df_filtered, y='Price', x=col, s=10, alpha=0.01, color='tab:green', height=3)\n",
    "    plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de correlación entre variables numéricas que caracterizan la vivienda y el precio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinamos la correlación entre variables numéricas que caracterizan la vivienda y el precio tanto analítica como gráficamente. A partir de esto, tomamos las siguientes decisiones:\n",
    "* YearBuilt: tanto la correlación con el precio (-0.33) como la gráfica nos dan una tendencia clara de que cuanto más antigüa es la vivienda, mayor es su precio, concentrándose los menores precios en las más recientes. La consideramos en el dataset.\n",
    "* Landsize: si bien la correlación con el precio es baja (0.25), no debemos dejar de lado que es una correlación lineal. Al ver la gráfica, tenemos claramente dos *poblaciones* bien marcadas para el tamaño de la propiedad. Además, éstas se concentran para precios bajos. Consideramos que es una variable importante para predecir el valor de la propiedad y la consideramos en el dataset.\n",
    "* BuildingArea: tiene una mayor correlación que Landsize (0.54), lo cual tiene sentido al tener una única *población* en su gráfica. Hay una marcada tendencia entre tamaños y precios, por lo que la consideramos en el dataset. \n",
    "* Rooms: la correlación con el precio es de 0.50 y esto se ve reflejado en su gráfica, por lo que consideramos que es importante para la predicción del valor de la propiedad.\n",
    "* Bedroom2: es totalmente análogo el caso Rooms, por lo que la consideraremos en el dataset.\n",
    "* Bathroom: pasa algo similar a los 2 casos anteriores, aunque no es tan marcado. La consideraremos en el dataset.\n",
    "* Car: la correlación con el precio es de 0.24 y su gráfica no indica una tendencia muy clara, por lo que la descartamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de coeficientes de correlación con el precio\n",
    "corr = df_filtered[num_home].corr()['Price']\n",
    "print(corr.drop('Price'))\n",
    "\n",
    "# Gráfica de correlaciones con el precio\n",
    "for col in num_home:\n",
    "    if col == 'Price':\n",
    "        continue\n",
    "    else:\n",
    "        sns.jointplot(data=df_filtered, y='Price', x=col, s=10, alpha=0.01, color='tab:green', height=3)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables numéricas elegidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo listado de variables numéricas de interés\n",
    "sel_num = ['Distance', 'Lattitude', 'Longtitude', \n",
    "            'YearBuilt', 'Landsize', 'BuildingArea', 'Rooms', \n",
    "            'Bedroom2', 'Bathroom', 'Price']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de variables categóricas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para decidir sobre este tipo de variables, consideraremos conjuntamente la cardinalidad de cada variable y el porcentaje de repeticiones que tienen los 10 registros mayoritarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado de variables categóricas geográficas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suburb tiene 311 valores diferentes. El valor mayoritario contribuye en un 2.66% y los 10 primeros en conjunto contribuyen al 17.09%. Descartamos entonces esta variable del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_geo[0]].nunique())\n",
    "a = 100*df_filtered[cat_geo[0]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Address tiene 13232 valores diferentes. El valor mayoritario contribuye en un 0.02% y los 10 primeros en conjunto contribuyen al 0.22%. Descartamos entonces esta variable del dataset.\n",
    "\n",
    "**Observación:** más allá de estos números, descartamos esta variable ya que la dirección es única para cada propiedad y no es representativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_geo[1]].nunique())\n",
    "a = 100*df_filtered[cat_geo[1]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CouncilArea tiene 33 valores diferentes. El valor mayoritario contribuye en un 9.59% y los 10 primeros en conjunto contribuyen al 68.61%. Esta variable no será descartada del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_geo[2]].nunique())\n",
    "a = 100*df_filtered[cat_geo[2]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regionname tiene 8 valores diferentes. El valor mayoritario contribuye en un 34.54% y los 10 primeros en conjunto contribuyen al 100%. Esta variable no será descartada del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_geo[3]].nunique())\n",
    "a = 100*df_filtered[cat_geo[3]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postcode tiene 196 valores diferentes. El valor mayoritario contribuye en un 2.65% y los 10 primeros en conjunto contribuyen al 20.32%. La descartaríamos, pero la conservamos ya que será nuestro punto de unión entre datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_geo[4]].nunique())\n",
    "a = 100*df_filtered[cat_geo[4]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado de variables categóricas que caracterizan a la vivienda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method tiene 5 valores diferentes. El valor mayoritario contribuye en un 66.52% y estos 5 contribuyen al 100%. Esta variable no será descartada del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_home[0]].nunique())\n",
    "a = 100*df_filtered[cat_home[0]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SellerG tiene 267 valores diferentes. El valor mayoritario contribuye en un 11.53% y los 10 primeros en conjunto contribuyen al 59.53%. Esta variable no será descartada del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_home[1]].nunique())\n",
    "a = 100*df_filtered[cat_home[1]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date tiene 58 valores diferentes. El valor mayoritario contribuye en un 3.48% y los 10 primeros en conjunto contribuyen al 26.77%. Descartamos entonces esta variable del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_home[2]].nunique())\n",
    "a = 100*df_filtered[cat_home[2]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type tiene 3 valores diferentes. El valor mayoritario contribuye en un 70.04% y estos 3 contribuyen al 100%. Esta variable no será descartada del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad:', df_filtered[cat_home[3]].nunique())\n",
    "a = 100*df_filtered[cat_home[3]].value_counts(normalize=True).iloc[:10]\n",
    "print(a)\n",
    "print(np.sum(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables categóricas elegidas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las variables de mayor cardinalidad (CouncilArea y SellerG), agruparemos todos los registros que que contribuyen en menos del 2% en un nuevo registro \"Other\". De esta manera pasamos de tener 220 valores únicos para SellerG y 28 para CouncilArea, a tener 13 y 18 valores únicos, respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['SellerG', 'CouncilArea']:\n",
    "  value_counts = 100 * df_filtered[col].value_counts(normalize=True)\n",
    "  lower_values = value_counts[value_counts < 2].index.tolist()\n",
    "  df_filtered[col] = df_filtered[col].apply(lambda x: 'Other' if x in lower_values else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['SellerG', 'CouncilArea']:\n",
    "    print(col)\n",
    "    print('\\tCardinalidad:', df_filtered[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preselección de variables categóricas de interés\n",
    "sel_cat = ['CouncilArea', 'Regionname', 'Method', 'SellerG', 'Type', 'Postcode']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos los boxplots para las variables categóricas preseleccionadas. Salvo para Method, en todos los demás casos vemos que se pueden establecer tendencias entre el valor de la variable categórica y el precio, por lo que nos quedamos con CouncilArea, Regionname, SellerG y Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sel_cat[:-1]:\n",
    "  values = df_filtered[col].value_counts(normalize=True).index[:10].tolist()\n",
    "  plt.figure(figsize=(6, 5))\n",
    "  sns.boxplot(data=df_filtered[df_filtered[col].isin(values)], y=col, x='Price')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo listado de variables categóricas de interés\n",
    "sel_cat = ['CouncilArea', 'Regionname', 'SellerG', 'Type', 'Postcode']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado del DataFrame por variables seleccionadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un nuevo DataFrame donde nos quedamos únicamente con las columnas de interés, ya teniendo ciertos filtros aplicados. Pasamos de tener 21 variables y 13.580 registros a tener 15 variables y 9.418 registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_cols = sel_num + sel_cat\n",
    "print(f'Cantidad de variables: {len(sel_cols)}.')\n",
    "\n",
    "df = df_filtered.copy()\n",
    "df = df[sel_cols]\n",
    "print(f'Cantidad de registros: {len(df)}.')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Unión de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df = pd.read_csv('https://cs.famaf.unc.edu.ar/~mteruel/datasets/diplodatos/cleansed_listings_dec18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estandariza el tipo de datos para la columna zipcode\n",
    "airbnb_df['zipcode'] = pd.to_numeric(airbnb_df.zipcode, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.zipcode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza un scatter plot para apreciar cuántas entradas hay para cada zipcode\n",
    "sns.scatterplot(data=airbnb_df.zipcode.value_counts().values) # Agregué 'data=' para que funcione sns\n",
    "plt.axhline(100, color='g')\n",
    "plt.xlabel(\"Índice (zipcodes ordenados de mayor a menor en #repeticiones)\")\n",
    "plt.ylabel(\"#repeticiones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(airbnb_df.zipcode.value_counts()[airbnb_df.zipcode.value_counts()<100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aquí en adelante solo consideraremos los zipcodes que tengan una cantidad mayor o igual a 100 registros para que la información agregada sea relevante. De acuerdo al análisis anterior, esto implica eliminar 199 zipcodes. Destacamos que el zipcode más abundante es \"3000\", el cual aparece 3367 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = airbnb_df.zipcode.value_counts()\n",
    "value_counts = value_counts[value_counts>=100]\n",
    "airbnb_df_reducido = airbnb_df.copy()  # Copio el df para que no se pierda el anterior\n",
    "airbnb_df_reducido = airbnb_df_reducido[airbnb_df_reducido['zipcode'].isin(value_counts.index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_price_by_zipcode = airbnb_df_reducido.groupby('zipcode')\\\n",
    "  .agg({'price': ['mean', 'count'], 'weekly_price': 'mean',\n",
    "        'monthly_price': 'mean', 'number_of_reviews': ['sum', 'mean'],\n",
    "        'review_scores_rating': ['min', 'max', 'mean']})\\\n",
    "  .reset_index()\n",
    "# Flatten the two level columns\n",
    "airbnb_price_by_zipcode.columns = [\n",
    "  ' '.join(col).strip()\n",
    "  for col in airbnb_price_by_zipcode.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_price_by_zipcode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "airbnb_price_by_zipcode = airbnb_price_by_zipcode.rename(\n",
    "    columns={'price mean': 'airbnb_price_mean',\n",
    "             'price count': 'airbnb_record_count',\n",
    "             'weekly_price mean': 'airbnb_weekly_price_mean',\n",
    "             'monthly_price mean': 'airbnb_monthly_price_mean',\n",
    "             'number_of_reviews sum': 'airbnb_number_of_reviews_sum', \n",
    "             'number_of_reviews mean': 'airbnb_number_of_reviews_mean', \n",
    "             'review_scores_rating min': 'airbnb_review_scores_rating_min', \n",
    "             'review_scores_rating max': 'airbnb_review_scores_rating_max',\n",
    "             'review_scores_rating mean': 'airbnb_review_scores_rating_mean'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_price_by_zipcode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.merge(\n",
    "    airbnb_price_by_zipcode, how='left',\n",
    "    left_on='Postcode', right_on='zipcode'\n",
    ")\n",
    "df_join.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Otras posibilidades"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se podría utilizar la variable Suburb que se encuentra en ambos datasets y posee una cardinalidad mayor al código postal en ambos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad Código postal:', melb_df.Postcode.nunique())\n",
    "print('Cardinalidad Suburbio:', melb_df.Suburb.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cardinalidad Código postal:', airbnb_df.zipcode.nunique())\n",
    "print('Cardinalidad Suburbio:', airbnb_df.suburb.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción sería utilizar la latitud y longitud que se encuentra en ambos datasets y encontrar todas las propiedades que se encuentren a cierta distancia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 3 - Guardado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el dataset en un archivo csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Para crear el archivo csv en el cwd sin tener que usar colab.\n",
    "df_join.to_csv('./GuardadoFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1NXWXyebR6mzAabyOPqghXpZQdyy05cRV",
     "timestamp": 1680785357097
    },
    {
     "file_id": "1OZLULlr-RkXwyhar7ED5fcXmPdgc6tGb",
     "timestamp": 1617224538047
    },
    {
     "file_id": "1xPL68eVaR0UF7XTcLU1rCMfpzuS7r6s0",
     "timestamp": 1617223947184
    },
    {
     "file_id": "1bChseZSrdGJSXfa-D2_lS0dx98wplQtD",
     "timestamp": 1614968149245
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
