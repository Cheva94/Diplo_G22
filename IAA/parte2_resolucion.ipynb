{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al aprendizaje automático\n",
    "\n",
    "### Trabajo práctico entregable - Grupo 22 - Parte 2\n",
    "Armado de un esquema de aprendizaje automático\n",
    "\n",
    "**Integrantes:**\n",
    "- Chevallier-Boutell, Ignacio José\n",
    "- Ribetto, Federico Daniel\n",
    "- Rosa, Santiago\n",
    "- Spano, Marcelo\n",
    "\n",
    "**Seguimiento:** Meinardi, Vanesa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno\n",
    "import sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y división en entrenamiento y evaluación\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "\n",
    "# División entre instancias y etiquetas\n",
    "X, y = dataset.iloc[:, 1:], dataset.TARGET\n",
    "\n",
    "msno.bar(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Documentación:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Antes de responder a las preguntas, veamos la descripción del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan dataset based on the Kaggle Home Equity dataset\t\n",
    "Available at: https://www.kaggle.com/ajay1735/hmeq-data\t\n",
    "\t\n",
    "## Context\t\n",
    "## -----------------------------------------------\n",
    "\n",
    "The consumer credit department of a bank wants to automate the decisionmaking process for approval of home equity lines of credit. To do this, they will follow the recommendations of the Equal Credit Opportunity Act to create an empirically derived and statistically sound credit scoring model. The model will be based on data collected from recent applicants granted credit through the current process of loan underwriting. The model will be built from predictive modeling tools, but the created model must be sufficiently interpretable to provide a reason for any adverse actions (rejections).\t\n",
    "\n",
    "## Content\t\n",
    "## -----------------------------------------------\n",
    "\n",
    "The Home Equity dataset (HMEQ) contains baseline and loan performance information for 5960 recent home equity loans. The target (BAD) is a binary variable indicating whether an applicant eventually defaulted or was seriously delinquent. This adverse outcome occurred in 1189 cases (20%). For each applicant, 12 input variables were recorded.\n",
    "\n",
    "## Attributes\t\n",
    "## -----------------------------------------------\n",
    "\n",
    "* Name:    Description.\t\n",
    "* TARGET:  Label. 1 = client defaulted on loan; - 0 = loan repaid.\t\n",
    "* LOAN:    Amount of the loan request.\n",
    "* MORTDUE: Amount due on existing mortgage.\t\n",
    "* VALUE:   Value of current property.\n",
    "* YOJ:     Years at present job.\n",
    "* DEROG:   Number of major derogatory reports.\t\n",
    "* DELINQ:  Number of delinquent credit lines.\n",
    "* CLAGE:   Age of oldest trade line in months.\n",
    "* NINQ:    Number of recent credit lines.\n",
    "* CLNO:    Number of credit lines.\n",
    "* DEBTINC: Debt-to-income ratio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora respondemos a las preguntas.\n",
    "\n",
    "1. *¿De qué se trata el conjunto de datos?* El dataset proviene de Kaggle, contiene datos financieros de 5960 préstamos. La idea del departamento de créditos del banco es automatizar el proceso de toma de decisiones entrenando un modelo con este dataset.\n",
    "\n",
    "\n",
    "2. *¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?* La variable objetivo que hay que predecir es **Target**, la cual indica si se le va a otorgar un crédito a la persona solicitante o no.\n",
    "\n",
    "\n",
    "3. *¿Qué información (atributos) hay disponible para hacer la predicción?* Las variables disponibles del dataset para hacer la predicción son:\n",
    "\n",
    "* **LOAN**:    Variable numérica. Cantidad del préstamo.\n",
    "* **MORTDUE**: Variable numérica. Lo que ya debe la persona?.\t\n",
    "* **VALUE**:   Variable numérica. Valor de la propiedad.\n",
    "* **YOJ**:     Variable numérica. Años en el presente trabajo.\n",
    "* **DEROG**:   Variable numérica. Número de reportes negativos.\t\n",
    "* **DELINQ**:  Variable numérica. Número de líneas crediticias delinquivas?.\n",
    "* **CLAGE**:   Variable numérica. Edad de la 'trade line' (sea lo que sea esto) en meses.\n",
    "* **NINQ**:    Variable numérica. Número de líneas de crédito recientes.\n",
    "* **CLNO**:    Variable numérica. Número de líneas de crédito (totales?).\n",
    "* **DEBTINC**: Variable numérica. tasa deuda-ingreso.\n",
    "\n",
    "\n",
    "4. *¿Qué atributos imagina ud. que son los más determinantes para la predicción?* En orden de importancia: \n",
    "\n",
    "- **Loan**: El tamaño del préstamo tiene que ser relevante.\n",
    "- **DEBTINC**: Esta variable indica directamente la cantidad real de ingresos que una persona dispone. \n",
    "- **MORTDUE**: Lo que debe la persona claramente tiene que ser relevante.\\\n",
    "- **YOJ**: Si bien no creo que sea tan determinante, mucho tiempo en el mismo trabajo al menos implica un flujo constante de dinero.\n",
    "- **DELINQ**: Esta variable nos dice directamente cuántos créditos no pudo pagar. Tiene que ser importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Predicción con Modelos Lineales\n",
    "\n",
    "En este ejercicio se entrenarán modelos lineales de clasificación para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase SGDClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador SGDClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del SGDClassifier. Como mínimo, probar diferentes funciones de loss, tasas de entrenamiento y tasas de regularización.\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Árboles de Decisión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: DecisionTreeClassifier con hiperparámetros por defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, es importante evaluar estadisticamente el comportamiento de nuestro modelo. Una posibilidad es comparar los valores predichos por el árbol con los valores observados para un conjunto relativamente grande de casos. Este conjunto es el que denominamos conjunto de \"testing\". \n",
    "Podemos utilizar una tabla o **matriz de contingencia** para calcular las frecuencias relativas de los eventos. En la literatura de machine learning esta matriz se la llama **matriz de confusión** (confusion matrix).\n",
    "\n",
    "Los elementos de la matriz son:\n",
    "\n",
    "* TP - verdaderos positivos: se pronosticó el pago del cŕedito y ocurrió (aciertos, hits)\n",
    "* TN - verdaderos negativos: se pronosticó el default y ocurrió (aciertos negativos)\n",
    "* FN - falsos negativos o sorpresas: se pronosticó el pago del cŕedito y ocurrió un default (misses)\n",
    "* FP - falsos positivos o falsa alarma: se pronosticó un default pero se pagó el crédito (false alarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen multiples índices (scores) que pueden calcularse a partir de la matriz de contingencia:\n",
    "\n",
    "$$\\text{Precision}=\\frac{TP}{TP+FP}$$\n",
    "\n",
    "es la porción de eventos pronosticados que resultó en una correcta detección. El valor va entre 0 y 1, siendo este último el valor óptimo.\n",
    "\n",
    "$$\\text{Accuracy} =\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "es la fracción de eventos pronosticados correctamente sobre todas las predicciones.\n",
    "\n",
    "$$\\text{Recall} = \\frac{TP}{FN+TP}$$\n",
    "\n",
    "es la fracción de eventos positivos observados que fueron correctamente pronosticados. El valor va entre 0 y 1, siendo este último el valor óptimo.\n",
    "\n",
    "$$ \\text{F1} =\\frac{ precision * recall} {precision + recall} $$\n",
    "\n",
    "es una media armónica de la precisión y el recall. Toma valores entre 0 y 1, siendo 1 el mejor valor y 0 el peor.\n",
    "\n",
    "$$\\text{false alarm ratio} = \\frac{FP}{TP+FP}$$\n",
    "\n",
    "es la porción de eventos pronosticados que resultó en una falsa detección. El valor va entre 0 y 1, siendo el primero el valor óptimo.\n",
    "\n",
    "$$\\text{bias} = \\frac{TP+FP}{TP+FN}$$\n",
    "\n",
    "es la relación entre la frecuencia con la que se pronostica el evento y la frecuencia con la que el evento ocurre. Su valor está entre menos infinito e infinito. El valor óptimo es 1.\n",
    "\n",
    "$$\\text{Critical success index} = \\frac{TP}{TP+FP+FN}$$\n",
    "\n",
    "El ETS es similar al CSI pero remueve el efecto de los aciertos que pueden ocurrir por azar. Su valor máximo es 1, que también es el valor óptimo.\n",
    "\n",
    "Notar que estos índices se orientan hacia la categoría de más interés (en este caso, que se haya pagado el crédito). Lo que se mide son aciertos en el pago del crédito o falsas detecciones del pago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores_class( y_pred , y_true ) :\n",
    "    \n",
    "    \"defino una funcion para calcular la matriz de contingencia, y varios scores\"\n",
    "    \n",
    "    cmatrix=sklearn.metrics.cluster.contingency_matrix( y_true , y_pred )\n",
    "\n",
    "    cmatrix_norm = cmatrix/np.sum(cmatrix)\n",
    "        \n",
    "    tp = cmatrix_norm[0,0]\n",
    "    fp = cmatrix_norm[1,0]\n",
    "    tn = cmatrix_norm[1,1]\n",
    "    fn = cmatrix_norm[0,1]\n",
    "    n  = np.sum( cmatrix_norm ) #Esto deberia dar siempre 1 si la matriz esta normalizada. \n",
    "    \n",
    "    model_pre = tp / (tp+fp)\n",
    "    model_acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    model_rec = tp / ( fn + tp )\n",
    "    model_far = fp / ( tp + fp )\n",
    "    model_bias= ( tp + fp ) / ( tp + fn )\n",
    "    model_csi = tp / ( tp + fp + fn )\n",
    "    model_random_hits = ((tp+fp)*(tp+fn))/n\n",
    "    model_ets = ( tp - model_random_hits ) / ( tp + fp + fn - model_random_hits )\n",
    "    F1 = 2 * (model_pre * model_rec) / (model_pre + model_rec)\n",
    "    \n",
    "    index = {\"FAR\":model_far,\"BIAS\":model_bias,\"F1\":F1,\n",
    "               \"CSI\":model_csi,\"RND\":model_random_hits,\"ETS\":model_ets,\n",
    "               \"PREC\":model_pre,\"ACC\":model_acc,\"REC\":model_rec}\n",
    "    \n",
    "    return cmatrix_norm, index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestros conjuntos de entrenamiento y evaluación con las variables predictoras que quiero usar. Corroboro que en los conjuntos de entrenamiento y evaluación, la relación de etiquetas 'default' y 'repago' se mantengan respecto del dataset total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#[\"LOAN\",\"MORTDUE\",\"VALUE\",\"YOJ\",\"DEROG\",\"DELINQ\",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"]\n",
    "\n",
    "predictores = [\"LOAN\",\"VALUE\",\"DEBTINC\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# los datos deben estar en arrays\n",
    "x_values = np.array([dataset[x] for x in predictores], dtype=object).transpose()\n",
    "y_values = dataset[\"TARGET\"]  #variable a predecir\n",
    "\n",
    "# separamos los datos en entrenamiento (train) y testeo (testeo)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, random_state = 78014,\n",
    "                                                    test_size = 0.2, shuffle=True)\n",
    "\n",
    "#Corroboro que están bien distribuidos los datos\n",
    "loans_d_tot = len(dataset[dataset[\"TARGET\"]==1])\n",
    "loans_r_tot = len(dataset[dataset[\"TARGET\"]==0])\n",
    "print(\"default/repaid total ratio:\",loans_d_tot/loans_r_tot)\n",
    "\n",
    "loans_d_train = len(y_train[y_train==1])\n",
    "loans_r_train = len(y_train[y_train==0])\n",
    "print(\"default/repaid train ratio:\",loans_d_train/loans_r_train)\n",
    "\n",
    "loans_d_test = len(y_test[y_test==1])\n",
    "loans_r_test = len(y_test[y_test==0])\n",
    "print(\"default/repaid test ratio:\",loans_d_test/loans_r_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entreno ahora un árbol de decisión con profundidad 2, que es la profundidad mínima donde se pronostica que se repagan algunos créditos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Entreno el arbol\n",
    "depth=3\n",
    "tree_loan = DecisionTreeClassifier(max_depth = depth, splitter='best')\n",
    "tree_loan.fit(x_train, y_train)\n",
    "y_pred = tree_loan.predict(x_test)\n",
    "\n",
    "tree.plot_tree(tree_loan, \n",
    "               feature_names = predictores,\n",
    "               class_names = [\"d\",\"r\"],   #d=default, #r=repaid\n",
    "               rounded=True, \n",
    "               filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos ahora qué tan bien se comporta nuestro modelo. \n",
    "\n",
    "Para eso, primero veamos la matriz de contingencia. Observamos que todos los aciertos del modelo está al pronosticar que la gente pagó su crédito, pero no detectó ningún caso de gente que terminó en default.\n",
    "\n",
    "Esto se puede analizar mejor con los índices antes definidos:\n",
    "* La exactitud, precisión y índice de acierto rítico son básicamente los mismos ya que el modelo predice sólo una clase.\n",
    "* El recall es 1 por la misma razón, no hay verdaderos negativos.\n",
    "* Qué podemos decir sobre el F1??? \n",
    "* El modelo es propenso a sobreestimar el default: 15% de los casos, viendo la tasa de falsas alarmas. El bias > 1 también indica este fenómeno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix, index = compute_scores_class( y_pred , y_test )\n",
    "\n",
    "res = sns.heatmap(cmatrix , \n",
    "                  annot=True, \n",
    "                  fmt='.2f', \n",
    "                  cmap=\"YlGnBu\", \n",
    "                  vmin=0.0, \n",
    "                  vmax=1.0 , \n",
    "                  xticklabels=[0,1],\n",
    "                  yticklabels=[0,1])\n",
    "\n",
    "print(\"precisión: \", index[\"PREC\"])\n",
    "print(\"exactitud: \", index[\"ACC\"])\n",
    "print(\"Recall: \", index[\"REC\"])\n",
    "print(\"F1: \",index[\"F1\"])\n",
    "print(\"tasa de falsas alarmas: \", index[\"FAR\"])\n",
    "print(\"bias: \", index[\"BIAS\"])\n",
    "print(\"índice de acierto crítico: \", index[\"CSI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del DecisionTreeClassifier. Como mínimo, probar diferentes criterios de partición (criterion), profundidad máxima del árbol (max_depth), y cantidad mínima de samples por hoja (min_samples_leaf).\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "max_depth = [3,4,5,6,7,8,9,10]\n",
    "min_samples_leaf = [1,2,3,4,5]\n",
    "\n",
    "#defino el modelo\n",
    "tree_loan = DecisionTreeClassifier()\n",
    "\n",
    "#defino el diccionario de parámetros para armar la grilla\n",
    "params = {'criterion': criterion,'max_depth': max_depth,'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "#Instancio el objeto de búsqueda\n",
    "trees = GridSearchCV(\n",
    "        estimator=tree_loan,   #mi estimador \n",
    "        param_grid=params,     #la grilla donde voy a variar los hiperparámetros\n",
    "        cv=None,               #None to use 5-fold cross-validation\n",
    "        n_jobs=4,              #4 búsquedas en simultáneo\n",
    "        verbose=1          \n",
    "        )\n",
    "\n",
    "#realizo la búsqueda\n",
    "trees.fit(x_train, y_train)\n",
    "#mejores parámetros:\n",
    "print(trees.cv_results_)\n",
    "\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "# tree.plot_tree(tree_loan, \n",
    "#                feature_names = predictores,\n",
    "#                class_names = [\"d\",\"r\"],   #d=default, #r=repaid\n",
    "#                rounded=True, \n",
    "#                filled=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
