{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al aprendizaje automático\n",
    "\n",
    "### Trabajo práctico entregable - Grupo 22 - Parte 2\n",
    "Armado de un esquema de aprendizaje automático\n",
    "\n",
    "**Integrantes:**\n",
    "- Chevallier-Boutell, Ignacio José\n",
    "- Ribetto, Federico Daniel\n",
    "- Rosa, Santiago\n",
    "- Spano, Marcelo\n",
    "\n",
    "**Seguimiento:** Meinardi, Vanesa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y división en entrenamiento y evaluación\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "\n",
    "# División entre instancias y etiquetas\n",
    "X, y = dataset.iloc[:, 1:], dataset.TARGET\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Documentación:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Antes de responder a las preguntas, veamos la descripción del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan dataset based on the Kaggle Home Equity dataset\t\n",
    "Available at: https://www.kaggle.com/ajay1735/hmeq-data\t\n",
    "\t\n",
    "## Context\t\n",
    "## -----------------------------------------------\n",
    "\n",
    "The consumer credit department of a bank wants to automate the decisionmaking process for approval of home equity lines of credit. To do this, they will follow the recommendations of the Equal Credit Opportunity Act to create an empirically derived and statistically sound credit scoring model. The model will be based on data collected from recent applicants granted credit through the current process of loan underwriting. The model will be built from predictive modeling tools, but the created model must be sufficiently interpretable to provide a reason for any adverse actions (rejections).\t\n",
    "\n",
    "## Content\t\n",
    "## -----------------------------------------------\n",
    "\n",
    "The Home Equity dataset (HMEQ) contains baseline and loan performance information for 5960 recent home equity loans. The target (BAD) is a binary variable indicating whether an applicant eventually defaulted or was seriously delinquent. This adverse outcome occurred in 1189 cases (20%). For each applicant, 12 input variables were recorded.\n",
    "\n",
    "## Attributes\t\n",
    "## -----------------------------------------------\n",
    "\n",
    "* Name:    Description.\t\n",
    "* TARGET:  Label. 1 = client defaulted on loan; - 0 = loan repaid.\t\n",
    "* LOAN:    Amount of the loan request.\n",
    "* MORTDUE: Amount due on existing mortgage.\t\n",
    "* VALUE:   Value of current property.\n",
    "* YOJ:     Years at present job.\n",
    "* DEROG:   Number of major derogatory reports.\t\n",
    "* DELINQ:  Number of delinquent credit lines.\n",
    "* CLAGE:   Age of oldest trade line in months.\n",
    "* NINQ:    Number of recent credit lines.\n",
    "* CLNO:    Number of credit lines.\n",
    "* DEBTINC: Debt-to-income ratio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora respondemos a las preguntas.\n",
    "\n",
    "1. *¿De qué se trata el conjunto de datos?* El dataset proviene de Kaggle, contiene datos financieros de 5960 préstamos. La idea del departamento de créditos del banco es automatizar el proceso de toma de decisiones entrenando un modelo con este dataset.\n",
    "\n",
    "\n",
    "2. *¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?* La variable objetivo que hay que predecir es **Target**, la cual indica si se le va a otorgar un crédito a la persona solicitante o no.\n",
    "\n",
    "\n",
    "3. *¿Qué información (atributos) hay disponible para hacer la predicción?* Las variables disponibles del dataset para hacer la predicción son:\n",
    "\n",
    "* **LOAN**:    Variable numérica. Cantidad del préstamo.\n",
    "* **MORTDUE**: Variable numérica. Lo que ya debe la persona?.\t\n",
    "* **VALUE**:   Variable numérica. Valor de la propiedad.\n",
    "* **YOJ**:     Variable numérica. Años en el presente trabajo.\n",
    "* **DEROG**:   Variable numérica. Número de reportes negativos.\t\n",
    "* **DELINQ**:  Variable numérica. Número de líneas crediticias delinquivas?.\n",
    "* **CLAGE**:   Variable numérica. Edad de la 'trade line' (sea lo que sea esto) en meses.\n",
    "* **NINQ**:    Variable numérica. Número de líneas de crédito recientes.\n",
    "* **CLNO**:    Variable numérica. Número de líneas de crédito (totales?).\n",
    "* **DEBTINC**: Variable numérica. tasa deuda-ingreso.\n",
    "\n",
    "\n",
    "4. *¿Qué atributos imagina ud. que son los más determinantes para la predicción?* En orden de importancia: \n",
    "\n",
    "- **Loan**: El tamaño del préstamo tiene que ser relevante.\n",
    "- **DEBTINC**: Esta variable indica directamente la cantidad real de ingresos que una persona dispone. \n",
    "- **MORTDUE**: Lo que debe la persona claramente tiene que ser relevante.\\\n",
    "- **YOJ**: Si bien no creo que sea tan determinante, mucho tiempo en el mismo trabajo al menos implica un flujo constante de dinero.\n",
    "- **DELINQ**: Esta variable nos dice directamente cuántos créditos no pudo pagar. Tiene que ser importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Predicción con Modelos Lineales\n",
    "\n",
    "En este ejercicio se entrenarán modelos lineales de clasificación para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase SGDClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador SGDClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del SGDClassifier. Como mínimo, probar diferentes funciones de loss, tasas de entrenamiento y tasas de regularización.\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Árboles de Decisión\n",
    "\n",
    "En este ejercicio se entrenarán árboles de decisión para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase DecisionTreeClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/tree.html\n",
    "  - https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: DecisionTreeClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador DecisionTreeClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores_class( y_pred , y_true ) :\n",
    "    \n",
    "    \"defino una funcion para calcular la matriz de contingencia, y varios scores\"\n",
    "    \n",
    "    cmatrix=sklearn.metrics.cluster.contingency_matrix( 1-y_true , 1-y_pred )\n",
    "    cmatrix_norm = cmatrix/np.sum(cmatrix)\n",
    "\n",
    "    tp = cmatrix_norm[0,0]\n",
    "    fp = cmatrix_norm[1,0]\n",
    "    tn = cmatrix_norm[1,1]\n",
    "    fn = cmatrix_norm[0,1]\n",
    "    n  = np.sum( cmatrix_norm ) #Esto deberia dar siempre 1 si la matriz esta normalizada. \n",
    "\n",
    "    model_pod = tp / ( fn + tp )\n",
    "    model_far = fp / ( tp + fp )\n",
    "    model_bias= ( tp + fp ) / ( tp + fn )\n",
    "    model_csi = tp / ( tp + fp + fn )\n",
    "    model_random_hits = ((tp+fp)*(tp+fn))/n\n",
    "    model_ets = ( tp - model_random_hits ) / ( tp + fp + fn - model_random_hits )\n",
    "\n",
    "    return cmatrix, model_pod , model_far , model_bias , model_csi , model_ets \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Defino mis predictores\"\n",
    "\n",
    "predictores = [\"rh\", \"windspeed\"]\n",
    "\n",
    "# los datos deben estar en arrays\n",
    "x_values = np.array([data[x] for x in predictores], dtype=object).transpose()\n",
    "y_values = data[\"niebla\"]\n",
    "\n",
    "#Removemos los datos faltantes . Para eso:\n",
    "#Generamos una mascara que es True para los valores en los que algun predictor es faltante \n",
    "#o bien el target es faltante. \n",
    "missing_data_mask = np.any( x_values == missing_value , axis = 1 )\n",
    "missing_data_mask[ y_values == missing_value ] = True\n",
    "\n",
    "x_values = x_values[ ~missing_data_mask ]\n",
    "y_values = y_values[ ~missing_data_mask ]\n",
    "\n",
    "# separamos los datos en entrenamiento (train) y testeo (testeo)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values,\n",
    "                                                    test_size = 0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Entreno el arbol:\"\n",
    "\n",
    "tree_niebla = DecisionTreeClassifier(max_depth = depth,splitter='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del DecisionTreeClassifier. Como mínimo, probar diferentes criterios de partición (criterion), profundidad máxima del árbol (max_depth), y cantidad mínima de samples por hoja (min_samples_leaf).\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
