{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al aprendizaje automático\n",
    "\n",
    "### Trabajo práctico entregable - Grupo 22 - Parte 2\n",
    "Armado de un esquema de aprendizaje automático\n",
    "\n",
    "**Integrantes:**\n",
    "- Chevallier-Boutell, Ignacio José\n",
    "- Ribetto, Federico Daniel\n",
    "- Rosa, Santiago\n",
    "- Spano, Marcelo\n",
    "\n",
    "**Seguimiento:** Meinardi, Vanesa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno\n",
    "import sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y división en entrenamiento y evaluación\n",
    "\n",
    "Las celdas siguientes se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio. Veamos la forma que tiene el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no hay datos faltantes en el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Antes de responder a las preguntas, veamos la descripción del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1: Descripción de los datos y la tarea\n",
    "\n",
    "Antes de responder a las preguntas, veamos la descripción del dataset (disponible en https://www.kaggle.com/ajay1735/hmeq-data).\n",
    "\n",
    "**Contexto:**\n",
    "\n",
    "El departamento de crédito al consumo de un banco quiere automatizar el proceso de toma de decisiones para la aprobación de líneas de crédito con garantía hipotecaria. Para hacer esto, seguirán las recomendaciones de la Ley de Igualdad de Oportunidades de Crédito para crear un modelo de puntuación de crédito estadísticamente sólido y derivado empíricamente. El modelo se basará en datos recopilados de solicitantes recientes a los que se les otorgó crédito a través del proceso actual de suscripción de préstamos. El modelo se construirá a partir de herramientas de modelado predictivo, pero el modelo creado debe ser suficientemente interpretable para proporcionar una razón para cualquier acción adversa (rechazos).\n",
    "\n",
    "**Contenido:**\n",
    "\n",
    "El conjunto de datos sobre el valor acumulado de la vivienda (HMEQ, por sus siglas en inglés) contiene información de línea de base y rendimiento de préstamos para 5960 préstamos sobre el valor acumulado de la vivienda recientes. El objetivo (target) (BAD) es una variable binaria que indica si un solicitante finalmente incumplió o fue gravemente moroso. Este resultado adverso ocurrió en 1189 casos (20%). Para cada solicitante se registraron 12 variables de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora pasamos a las preguntas:\n",
    "\n",
    "**1. ¿De qué se trata el conjunto de datos?**\n",
    "\n",
    "El dataset que vamos a utilizar es una versión ya curada de la proveniente de Kaggle, y contiene datos financieros de 1854 préstamos de un banco. La idea del departamento de créditos del banco es automatizar el proceso de toma de decisiones para la aprobación de préstamos hipotecarios creando y entrenando un modelo con este dataset.\n",
    "\n",
    "**2. ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?**\n",
    "\n",
    "La variable objetivo que hay que predecir es **TARGET**, la cual indica si se le va a otorgar un crédito a la persona solicitante o no. En caso de que el cliente haya incumplido con el préstamo esta variable toma el valor 1. En cambio, si el préstamo fue reembolsado, esta variable toma el valor 0.\n",
    "\n",
    "En el dataset provisto, la variable **TARGET** adopta el valor 0 en 1545 casos, y el valor 1 en los 309 casos restantes.\n",
    "\n",
    "**3. ¿Qué información (atributos) hay disponible para hacer la predicción?**\n",
    "\n",
    "Las variables disponibles en el dataset para hacer la predicción son:\n",
    "\n",
    "* **LOAN**:    Importe del préstamo (variable numérica).\n",
    "* **MORTDUE**: Cantidad adeudada en la hipoteca existente (variable numérica).\n",
    "* **VALUE**:   Valor de la propiedad actual (variable numérica).\n",
    "* **YOJ**:     Años de la persona en el trabajo actual (variable numérica).\n",
    "* **DEROG**:   Número de reportes negativos (variable numérica).\t\n",
    "* **DELINQ**:  Número de líneas de crédito morosas (variable numérica).\n",
    "* **CLAGE**:   Edad de la línea comercial más antigua en meses (variable numérica).\n",
    "* **NINQ**:    Número de líneas de crédito recientes (variable numérica).\n",
    "* **CLNO**:    Número de líneas de crédito (variable numérica).\n",
    "* **DEBTINC**: Relación deuda-ingresos (variable numérica).\n",
    "\n",
    "**4. ¿Qué atributos imagina ud. que son los más determinantes para la predicción?**\n",
    "\n",
    "En orden de importancia: \n",
    "\n",
    "- **LOAN**: El tamaño del préstamo tiene que ser relevante ya que, en principio, tiene sentido suponer que mientras mayor sea el préstamo, más difícil puede ser de pagar.\n",
    "- **DEROG y DELINQ**: Estas variables dan indicios directos de comportamientos negativos del solicitante.\n",
    "- **DEBTINC**: Esta variable indica directamente la cantidad real de ingresos que una persona dispone. \n",
    "- **MORTDUE**: Lo que debe la persona claramente tiene que ser relevante.\n",
    "- **YOJ**: Si bien no creemos que sea tan determinante, mucho tiempo en el mismo trabajo al menos implica un flujo constante de dinero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base al análisis del problema 1, dividimos el dataset en los conjuntos de entrenamiento y testeo, con los predictores mencionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de predictores posibles:\n",
    "#[\"LOAN\",\"MORTDUE\",\"VALUE\",\"YOJ\",\"DEROG\",\"DELINQ\",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"]\n",
    "\n",
    "#defino mis predictores:\n",
    "predictores = [\"LOAN\",\"MORTDUE\",\"DEBTINC\",\"YOJ\",\"DELINQ\"]\n",
    "#predictores = [\"LOAN\",\"MORTDUE\",\"VALUE\",\"YOJ\",\"DEROG\",\"DELINQ\",\"CLAGE\",\"NINQ\",\"CLNO\",\"DEBTINC\"]\n",
    "\n",
    "# separamos los datos en entrenamiento (train) y testeo (testeo)\n",
    "# los datos deben estar en arrays\n",
    "x_values = np.array([dataset[x] for x in predictores], dtype=object).transpose()\n",
    "y_values = dataset[\"TARGET\"]  #variable a predecir\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, random_state = 78014,\n",
    "                                                    test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de seguir, corroboramos que los conjuntos de entrenamiento y testeo están bien distribuidos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset shape:',dataset.shape)\n",
    "print('X_train shape:',x_train.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('X_test shape:',x_test.shape)\n",
    "print('y_test shape:',y_test.shape)\n",
    "print('*'*50)\n",
    "\n",
    "#Corroboramos que están bien distribuidos los datos:\n",
    "loans_d_tot = len(dataset[dataset[\"TARGET\"]==1])\n",
    "loans_r_tot = len(dataset[dataset[\"TARGET\"]==0])\n",
    "print(\"default/repaid total ratio:\",loans_d_tot/loans_r_tot)\n",
    "\n",
    "loans_d_train = len(y_train[y_train==1])\n",
    "loans_r_train = len(y_train[y_train==0])\n",
    "print(\"default/repaid train ratio:\",loans_d_train/loans_r_train)\n",
    "\n",
    "loans_d_test = len(y_test[y_test==1])\n",
    "loans_r_test = len(y_test[y_test==0])\n",
    "print(\"default/repaid test ratio:\",loans_d_test/loans_r_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante evaluar estadísticamente el comportamiento de nuestro modelo. Una posibilidad es comparar los valores predichos por el modelo con los valores observados para un conjunto relativamente grande de casos. Este conjunto es el que denominamos conjunto de \"testing\". \n",
    "Podemos utilizar la **matriz de confusión** para calcular las frecuencias relativas de los eventos.\n",
    "\n",
    "Los elementos de la matriz son:\n",
    "\n",
    "* TP - verdaderos positivos: se pronosticó el pago del cŕedito y ocurrió (aciertos, hits)\n",
    "* TN - verdaderos negativos: se pronosticó el default y ocurrió (aciertos negativos)\n",
    "* FN - falsos negativos o sorpresas: se pronosticó el pago del cŕedito y ocurrió un default (misses)\n",
    "* FP - falsos positivos o falsa alarma: se pronosticó un default pero se pagó el crédito (false alarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen multiples índices (scores) que pueden calcularse a partir de la matriz de confusión:\n",
    "\n",
    "**precision** es la porción de eventos pronosticados que resultó en una correcta detección. El valor va entre 0 y 1, siendo este último el valor óptimo:\n",
    "\n",
    "$$\\text{Precision}=\\frac{TP}{TP+FP}$$\n",
    "\n",
    "**accuracy** se define como la suma de verdaderos positivos y verdaderos negativos dividida por el número total de muestras. Esto solo es exacto si el modelo está equilibrado y dará resultados inexactos si hay un desequilibrio de clases:\n",
    "\n",
    "$$\\text{Accuracy} =\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "\n",
    "**recall** es la fracción de eventos positivos observados que fueron correctamente pronosticados. El valor va entre 0 y 1, siendo este último el valor óptimo:\n",
    "\n",
    "$$\\text{Recall} = \\frac{TP}{FN+TP}$$\n",
    "\n",
    "**F1** es una media armónica ponderada de la precisión y el recall. Toma valores entre 0 y 1, siendo 1 el mejor valor y 0 el peor.\n",
    "\n",
    "$$ \\text{F1} =2 * \\frac{ \\text{precision} * \\text{recall}} {\\text{precision} + \\text{recall}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicho todo esto, definimos una función para calcular la matriz de confusión y los scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores_class(y_test, y_pred) :\n",
    "    \n",
    "    \"defino una funcion para calcular la matriz de confusión, y varios scores\"\n",
    "    \n",
    "    cmatrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    tp = cmatrix[0,0]\n",
    "    fp = cmatrix[1,0]\n",
    "    tn = cmatrix[1,1]\n",
    "    fn = cmatrix[0,1]\n",
    "    \n",
    "    model_pre = tp / (tp+fp)\n",
    "    model_acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "    model_rec = tp / ( fn + tp )\n",
    "    F1 = 2 * (model_pre * model_rec) / (model_pre + model_rec)\n",
    "    \n",
    "    index = {\"f1\":F1,\"precision\":model_pre,\"accuracy\":model_acc,\"recall\":model_rec}\n",
    "    \n",
    "    return cmatrix, index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de hacer esto es con un *reporte de clasificación*, el cual muestra las principales métricas de clasificación: precision, recall, F1-score, y accuracy.\n",
    "\n",
    "La difierencia entre las dos formas de calcular los scores es que la función ``compute_scores_class`` usa todas las etiquetas juntas, mientras que la función ``precision_score`` de scikit learn diferencia entre etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Predicción con modelos lineales\n",
    "\n",
    "En este ejercicio se entrenaron modelos lineales de clasificación para predecir la variable objetivo utilizando la clase SGDClassifier de scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estimador ``SGDClasiffier`` implementa modelos lineales regularizados con aprendizaje de descenso de gradiente estocástico (SGD): el gradiente de la pérdida se estima cada muestra a la vez y el modelo se actualiza a lo largo del camino con un programa de fuerza decreciente (también conocido como tasa de aprendizaje).\n",
    "\n",
    "Utilizando los hiperparámetros por defecto obtenemos los siguientes resultados para la variable **TARGET**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos los resultados obtenidos\n",
    "model = SGDClassifier(random_state=0)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Escribimos los resultados obtenidos\n",
    "print('Predicción:')\n",
    "print(y_pred)\n",
    "print('*'*75)\n",
    "print('Conjunto de testeo:')\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos el desempeño del clasificador. Observamos que nuestro modelo no está prediciendo correcamente la etiqueta \"1\" (default). Se observa en los scores que tiene una alta precisión ya que predice muy bien los casos mayoritarios \"0\", pero con una exactitud mucho más baja ya que no está prediciendo nunca los 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cálculo de scores y matriz de confusión:\n",
    "cmat, index = compute_scores_class(y_test, y_pred)\n",
    "cmat2, index2 = compute_scores_class(1-y_test, 1-y_pred)\n",
    "\n",
    "\n",
    "for idx in index:\n",
    "    print(idx,':',index[idx])\n",
    "    \n",
    "for idx2 in index2:\n",
    "    print(idx2,':',index2[idx2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos el reporte de clasificación para comparar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tabla anterior muestra las métricas para cada clase (\"0\" y \"1\") y la ``accuracy`` para toda la muestra. Vemos que el clasificador es mucho más preciso para la clase \"0\", lo cual era de esperar tras ver los resultados predichos y notando que no hay ninguna etiqueta \"1\" entre ellos. Esta ausencia de etiquetas \"1\" también es causa de que para esta clase se cumpla que ``recall`` y ``F1-score`` sean nulos y que para la clase \"0\" el valor de ``recall`` sea 1.0. Notar que el valor 0.91 de ``F1-score`` no difiere mucho del de ``recall``, lo cual es un indicio de que la muestra está desbalanceada.\n",
    "\n",
    "\n",
    "Finalmente, la ``accuracy`` es de 0.83. Este valor, que puede ser considerado relativamente alto, refleja lo discutido previamente respecto a la capacidad del clasificador para clasificar correctamente las etiquetas \"0\", sumado al hecho de que hay aproximadamente cinco veces más muestras \"0\" que \"1\" (309 para \"1\" vs 62 para \"0\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cmat, ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta matriz nuevamente vemos cómo se manifiesta el hecho de que el clasificador no haya sido capaz de predecir etiquetas \"1\": Existe una gran diferencia entre los elementos diagonal y no-diagonal de la fila 1. Más específicamente, vemos que el elemento (1,1) de la matriz es cero mientras que el elemento (0,1) es 62."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.2: Ajuste de Hiperparámetros\n",
    "\n",
    "En este ejercicio repetimos lo hecho previamente pero ahora tomando diferentes valores para un dado conjunto de hiperparámetros del modelo. En particular, modificamos las funciones de pérdida, las tasas de entrenamiento y las tasas de regularización. Esto fue llevado a cabo mediante las técnicas ``grid-search`` y ``5-fold cross-validation`` sobre el conjunto de entrenamiento con el fin de explorar muchas combinaciones posibles de valores para los hiperparámetros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación cruzada (Cross-validation)\n",
    "\n",
    "Al evaluar diferentes hiperparámetros para los estimadores, existe el riesgo de sobreajuste en el conjunto de prueba porque los parámetros pueden modificarse hasta que el estimador funcione de manera óptima. De esta manera, el conocimiento sobre el conjunto de prueba puede \"filtrarse\" en el modelo y las métricas de evaluación ya no informan sobre el rendimiento de la generalización. Para resolver este problema, se puede presentar otra parte del conjunto de datos como un \"conjunto de validación\": el entrenamiento continúa en el conjunto de entrenamiento, después de lo cual se realiza la evaluación en el conjunto de validación y cuando el experimento parece tener éxito, la evaluación final se puede hacer en el conjunto de prueba.\n",
    "\n",
    "Sin embargo, al dividir los datos disponibles en tres conjuntos, reducimos drásticamente la cantidad de muestras que se pueden usar para aprender el modelo, y los resultados pueden depender de una elección aleatoria particular para el par de conjuntos (entrenamiento, validación).\n",
    "\n",
    "Una solución a este problema es un procedimiento llamado ``validación cruzada`` (CV). Todavía se debe reservar un conjunto de prueba para la evaluación final, pero el conjunto de validación ya no es necesario al hacer CV. En el enfoque básico, llamado k-fold CV, el conjunto de entrenamiento se divide en k conjuntos más pequeños. Para cada uno de los k “folds” se sigue el siguiente procedimiento:\n",
    "\n",
    "* Un modelo es entrenado usando $k-1$ de los folds como datos de entrenamiento;\n",
    "\n",
    "* El modelo resultante se valida con la parte restante de los datos (es decir, se utiliza como conjunto de prueba para calcular una medida de rendimiento como la precisión).\n",
    "\n",
    "La medida de rendimiento informada por  k-fold CV es un promedio de los valores calculados. Este enfoque puede ser computacionalmente costoso, pero no desperdicia demasiados datos, lo cual es una gran ventaja en problemas donde el número de muestras es muy pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada sobre una grilla de parámetros: GridSearchCV\n",
    "\n",
    "Con ``GridSearchCV`` podemos hacer validación cruzada (la cual, por defecto, es estratificada) sobre una grilla de parámetros dada considerando exhaustivamente todas las combinaciones de ellos. Sklearn se encarga de todo el proceso y nos devuelve una tabla de resultados junto con el mejor clasificador obtenido. Para ello es necesario especificar una grilla de valores para los parámetros de interés dentro de un diccionario. En particular, vamos a modificar los siguientes parámetros:\n",
    "\n",
    "* **Loss**: la función de costo. Usaremos ``hinge`` (SVM lineal), ``log_loss`` (regresión logística), ``squared_hinge`` (hinge cuadráticamente penalizado) y ``squared_error`` (error cuadrático).\n",
    "* **Penalty**: término de regularización. Probaremos con ``l2`` (regularizador estándar para modelos SVM) y ``elasticnet`` (combinación de ``l2`` con la norma absoluta ``l1``).\n",
    "* **Alpha**: la constante que multiplica al término de regularización. Barreremos el rango de valores [1e-5, 1e2] de forma logarítmica.\n",
    "\n",
    "Los valores por defecto de estos parámetros son ``loss='hinge'``, ``penalty='l2'`` y ``alpha=0.0001``.\n",
    "\n",
    "Debido al desbalance existente en el dataset, vamos a incrementar el número de \"folds\" a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDClassifier --> Valid parameters are: ['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon',\n",
    "# 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change','n_jobs',\n",
    "# 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'].\n",
    "\n",
    "# Primero creamos una lista logarítmica de valores de alpha\n",
    "alpha_list = np.logspace(-5, 1, 9, endpoint = True)\n",
    "#alpha_list=[0.0001,0.001,0.01,0.1,1]\n",
    "# Luego creamos el diccionario de parámetros de interés a explorar\n",
    "param_grid = {\n",
    "    'loss': ['log','hinge', 'log_loss','squared_hinge','squared_error'],\n",
    "    'alpha': alpha_list,\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'learning_rate':['constant','optimal','invscaling','adaptive'],\n",
    "    'eta0':alpha_list\n",
    "}\n",
    "\n",
    "# Aplicación del SGDClassifier\n",
    "model = SGDClassifier(random_state=0)\n",
    "\n",
    "cv = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=8, cv=10)\n",
    "cv.fit(x_train, y_train);\n",
    "\n",
    "results = cv.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.sort_values(by=['rank_test_score']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las 10 mejores combinaciones de parámetros quedan resumidas en la tabla anterior. En particular, la mejor combinación de parámetros es aquella dada por"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mejores parámetros:')\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de parámetros tiene asociado un score promedio de 0.83, con una desviación de 0.002.\n",
    "\n",
    "Ahora utilizaremos estos parámetros en el SGDClassifier para analizar el conjunto de testeo.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos los resultados obtenidos\n",
    "model2 = SGDClassifier(**cv.best_params_,random_state=0)\n",
    "model2.fit(x_train, y_train)\n",
    "y_pred2 = model2.predict(x_test)\n",
    "\n",
    "print('Predicción:')\n",
    "print(y_pred2)\n",
    "print('*'*75)\n",
    "print('Conjunto de testeo:')\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas:\n",
    "\n",
    "### Reporte de clasificación y matriz de confusión:\n",
    "\n",
    "Al igual que antes, hacemos un reporte de clasificación y calculamos la matriz de confusión para analizar el desempeño del clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Matriz de confusión:\n",
    "cmat2, index2 = compute_scores_class(y_test, y_pred2)\n",
    "\n",
    "for idx in index2:\n",
    "    print(idx,':',index2[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos el reporte de clasificación para comparar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred2)\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cmat2, ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los resultados coinciden con los obtenidos en el ejercicio previo. Esto puede deberse a que el dataset está desbalanceado, favoreciendo la predicción de la etiqueta \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Árboles de Decisión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: DecisionTreeClassifier con hiperparámetros por defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estimador ``DecisionTreeClassifier`` implementa árboles de decisión, que es una forma de aprendizaje automático no paramétrico. Las ventajas de este método son varias: es un modelo de caja blanca, es fácil de entender y visualizar, y requiere poca preparación de los datos, entre otras. angunas desventajas son: son propensos a overfittear, y son modelos con mucho bias, tendiendo a clasificar muy bien la clase dominante. \n",
    "\n",
    "Utilizando los hiperparámetros por defecto, obtenemos el siguiente árbol para la variable TARGET. Vemos que se crea un modelo muy profundo, lo que indica que el modelo está haciendo overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Entreno el arbol\n",
    "depth=1\n",
    "tree_loan = DecisionTreeClassifier()\n",
    "tree_loan.fit(x_train, y_train)\n",
    "y_pred = tree_loan.predict(x_test)\n",
    "\n",
    "tree.plot_tree(tree_loan, \n",
    "               feature_names = predictores,\n",
    "               class_names = [\"d\",\"r\"],   #d=default, #r=repaid\n",
    "               rounded=True, \n",
    "               filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas:\n",
    "\n",
    "### Reporte de clasificación y matriz de confusión:\n",
    "\n",
    "* La exactitud, precisión y recall de la clase '0' son muy parecidas ya que el modelo predice muy bien esta clase, por ser la mayoritaria. No es el caso para la clase '1': el modelo es muy exacto pero poco preciso y con un mal score de recall, ya que clasifica mal muchos casos.\n",
    "* El score F1 es similar al recall, indicando nuevamente que la muestra está desbalanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix, index = compute_scores_class( y_test, y_pred )\n",
    "cmatrix2, index2 = compute_scores_class( 1-y_test, 1-y_pred )\n",
    "\n",
    "for idx in index:\n",
    "    print(idx,':',index[idx])\n",
    "print(\"-\"*30)\n",
    "for idx2 in index2:\n",
    "    print(idx2,':',index2[idx2])\n",
    "\n",
    "    \n",
    "print(\"*\"*50)\n",
    "print(\"reporte:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora la matriz de confusión. La gran mayoría de los aciertos del modelo está al pronosticar que la gente pagó su crédito, pero detectó menos casos donde la gente terminó en default. De hecho, los falsos negativos son comparables a los falsos negativos, lo cual no es muy bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cmatrix, ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Ajuste de Hiperparámetros\n",
    "\n",
    "En este ejercicio repetimos lo hecho previamente pero ahora tomando diferentes valores para un dado conjunto de hiperparámetros del modelo. En particular, modificamos el criterio de búsqueda, la profundidad del árbol y el número mínimo de muestras requeridas para hacer la división de un nodo. Esto fue llevado a cabo mediante las técnicas ``grid-search`` y ``5-fold cross-validation`` sobre el conjunto de entrenamiento con el fin de explorar muchas combinaciones posibles de valores para los hiperparámetros, de forma similar a lo que hicimos en el problema 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "max_depth = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "min_samples_leaf = [1,2,3,4,5]\n",
    "\n",
    "#defino el modelo. Fijo la semilla para tener repetitividad del resultado.\n",
    "tree_loan = DecisionTreeClassifier(random_state=78014)\n",
    "\n",
    "#defino el diccionario de parámetros para armar la grilla\n",
    "params = {'criterion': criterion,'max_depth': max_depth,'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "#Instancio el objeto de búsqueda\n",
    "trees = GridSearchCV(\n",
    "        estimator=tree_loan,   #mi estimador \n",
    "        param_grid=params,     #la grilla donde voy a variar los hiperparámetros\n",
    "        cv=None,               #None to use 5-fold cross-validation\n",
    "        n_jobs=4,              #4 búsquedas en simultáneo\n",
    "        verbose=1          \n",
    "        )\n",
    "\n",
    "#realizo la búsqueda\n",
    "trees.fit(x_train, y_train)\n",
    "\n",
    "#mejores parámetros:\n",
    "opt_par = trees.best_params_\n",
    "\n",
    "print(\"*\"*50)\n",
    "print(\"Mejores parámetros:\")\n",
    "print(opt_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, veamos la forma que tiene el árbol entrenado con los parámetros encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_opt = DecisionTreeClassifier()\n",
    "\n",
    "depth = opt_par['max_depth']\n",
    "criterion = opt_par['criterion']\n",
    "min_samples_leaf = opt_par['min_samples_leaf']\n",
    "\n",
    "tree_opt = DecisionTreeClassifier(max_depth = depth, \n",
    "                                  criterion=criterion, \n",
    "                                  min_samples_leaf = min_samples_leaf\n",
    "                                 )\n",
    "tree_opt.fit(x_train, y_train)\n",
    "y_pred_opt = tree_opt.predict(x_test)\n",
    "\n",
    "tree.plot_tree(tree_opt, \n",
    "               feature_names = predictores,\n",
    "               class_names = [\"d\",\"r\"],   #d=default, #r=repaid\n",
    "               rounded=True, \n",
    "               filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas:\n",
    "\n",
    "### Reporte de clasificación y matriz de confusión:\n",
    "\n",
    "Al igual que antes, hacemos un reporte de clasificación y calculamos la matriz de confusión para analizar el desempeño del clasificador. El modelo óptimo clasifica muy bien la clase mayoritaria (gente que pagó el crédito) como era de esperar, pero no hubo mucha mejora en la clasificación de los casos de default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmatrix, index = compute_scores_class( y_test, y_pred )\n",
    "cmatrix2, index2 = compute_scores_class( 1-y_test, 1-y_pred )\n",
    "\n",
    "for idx in index:\n",
    "    print(idx,':',index[idx])\n",
    "print(\"-\"*30)\n",
    "for idx2 in index2:\n",
    "    print(idx2,':',index2[idx2])\n",
    "\n",
    "    \n",
    "print(\"*\"*50)\n",
    "print(\"reporte:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión nos indica un poco mejor lo que stá ocurriendo. El árbol óptimo clasifica mejor aún la clase '0' disminuyendo mucho los falsos positivos (es decir, predice default cuando pudo pagar el crédito), a costa de disminuir los aciertos de la clase '1' y aumentar los falsos negativos (es decir, predice que pagó el crédito cuando entró en default en realidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cmatrix, ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión:\n",
    "\n",
    "* Los árboles de decisión son más efectivos a la hora de predecir la clase minoritaria en nuestro dataset, comparada al clasificador SGD.\n",
    "\n",
    "* El árbol óptimo encontrado usando ``grid-search`` y ``5-fold cross-validation`` no es necesariamente mejor en nuestro problema particular por más que los scores sean ligeramente mejores ya que aumentan los falsos negativos, es decir el modelo otorgaría más créditos a gente que no los podría pagar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
