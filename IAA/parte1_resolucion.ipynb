{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplomatura en ciencia de datos, aprendizaje automático y sus aplicaciones - Edición 2023 - FAMAF (UNC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción al aprendizaje automático\n",
    "\n",
    "### Trabajo práctico entregable - Grupo 22 - Parte 1: Regresión en California\n",
    "\n",
    "**Integrantes:**\n",
    "- Chevallier-Boutell, Ignacio José\n",
    "- Ribetto, Federico Daniel\n",
    "- Rosa, Santiago\n",
    "- Spano, Marcelo\n",
    "\n",
    "**Seguimiento:** Meinardi, Vanesa\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos y vemos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Treamos la data (matriz con los datos de entrada / atributos) en X\n",
    "# y el target (vector de valores a predecir) en y, ambos como pandas DataFrame\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "\n",
    "# Traemos todo el dataset, con toda su descripción\n",
    "california = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(california['DESCR'])  # Descripción del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.head())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y.head())\n",
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentación del dataset: conjunto de entrenamiento y conjunto de evaluación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos aleatoriamente los datos en 80% para entrenamiento y 20% para evaluación. Nos quedan entonces 16.512 registros para entrenar y 4.128 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 1 - Descripción cualitativa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1 - ¿De qué se trata el conjunto de datos?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos el conjunto de datos *California house prices dataset* disponible en `sklearn`, obtenido a su vez del repositorio `StatLib`. En el mismo se ha recolectado información basada en el censo de California de 1990, donde cada fila representa un **grupo de bloques** (aunque quizás no sea totalmente correcto, de ahora en más nos referiremos a esto como **distrito**), *i.e.* la menor unidad geográfica para la cual la oficina de censos de EE.UU. publica datos, conteniendo entre 600 y 3.000 personas. Por otro lado, una vivienda (*household*) implica un grupo de personas que viven dentro de la misma casa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2 - ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable que pretende predecir este dataset nos indica la mediana del valor de las casas para los diferentes distritos en California, expresados en US$ 100.000."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3 - ¿Qué información (atributos) hay disponibles para hacer la predicción?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset tenemos 8 variables predictoras:\n",
    "1. MedInc: mediana del salario dentro del distrito.\n",
    "2. HouseAge: mediana de la antigüedad de las casas dentro del distrito.\n",
    "3. AveRooms: cantidad promedio de habitaciones por vivienda.\n",
    "4. AveBedrms: cantidad promedio de cuartos por vivienda.\n",
    "5. Population: población dentro del distrito.\n",
    "6. AveOccup: cantidad promedio de personas que viven dentro de la vivienda.\n",
    "7. Latitude y Longitude: ubicación geográfica del distrito.\n",
    "\n",
    "Para cada uno de estos atributos, contamos con 20.640 registros, lo cual nos lleva a una matriz de atributos de tamaño 20.640 $\\times$ 8."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4 - ¿Qué atributos imagina ud. que serán los más determinantes para la predicción?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el conjunto de datos pretende predecir el costo de las casas según el distrito, imaginamos que los atributos más influyentes serán:\n",
    "- MedInc: a mayor ingreso, mayor es el valor de la vivienda a la que alguien puede aspirar. \n",
    "- HouseAge: cuanto más vieja la propiedad, esta puede ser más barata.\n",
    "- Latitude y Longitude: seguramente existan diferencias en los precios entre barrios y eso nos lo puede dar la latitud y longitud."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5 - ¿Qué problemas observa a priori en el conjunto de datos? ¿Observa posibles sesgos, riesgos, dilemas éticos, etc? Piense que los datos pueden ser utilizados para hacer predicciones futuras."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que se tienen los valores promedios de habitaciones y cuartos por vivienda, los autores previenen que las columnas pueden presentar valores extremos por distrito con pocas viviendas así como muchas viviendas vacías, *e.g.* lugares para vacacionar.\n",
    "\n",
    "> **¿Algún otro problema?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 2 - Visualización"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realiza un scatterplot para la variable objetivo en función de cada uno de los atributos.\n",
    "\n",
    "A simple vista, se puede sacar las siguientes conclusiones:\n",
    "* Hay una relación creciente entre la variable MedInc (promedio del ingreso) y la variable objetivo.\n",
    "* En el caso de la Latitud y Longitud se puede observar que existen algunos rangos para los cuales la variable objetivo toma valores más bajos que para otros. \n",
    "Esto se puede observar para latitudes cercanas a 36 y superiores a 39 y para longitudes cercanas a -120, menores a -123 y mayores a -116.\n",
    "\n",
    "Para el resto de las variables es difícil sacar una conclusión con este tipo de gráficos ya que son muy ruidosos y, particularmente, AveRooms, AveBedrms, Population y AveOccup presentan valores extremos que terminan ocultando posibles tendencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns\n",
    "\n",
    "row, col = 0, 0\n",
    "fig, axs = plt.subplots(2,4, figsize=(16, 10))  \n",
    "for i in range(len(features)):\n",
    "    row = i // 4  # Calculate the row index\n",
    "    col = i % 4   # Calculate the column index\n",
    "    axs[row, col].scatter(X[features[i]], y, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"datos\")\n",
    "    axs[row, col].grid()\n",
    "    axs[row, col].set_axisbelow(True)  # Set the grid behind the plot\n",
    "    # Add y-axis label only for the first column in each row\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel(\"MedHouseVal\")\n",
    "    axs[row, col].set_xlabel(features[i])  # Add subplot title\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realizó otra representación. Cada atributo se dividió en 8 cuantiles y se realizaron boxplots de la variable objetivo para observar sus diferencias.\n",
    "\n",
    "La ventaja de estos gráficos es que podemos observar las diferencias en las medianas para cada cuantil así como la dispersión de valores.\n",
    "\n",
    "A ojo se puede concluir:\n",
    "* MedInc: La mediana para cada cuantil es creciente, lo cual refuerza lo visto en el scatterplot y la conclusión de que esta variable y la variable objetivo poseen una relación creciente.\n",
    "* HouseAge: No parece haber una dependencia importante en la variable objetivo con la antigüedad promedio de las casas. Se puede observar un ligero crecimiento en la mediana para el último cuantil.\n",
    "* AveRooms: Para los cuantiles 0 a 4 no se aprecia una diferencia de comportamiento para la variable objetivo. Sin embargo, a partir del cuantil 5 se observa un crecimiento en la mediana lo que indica una relación creciente entre ambas variables.\n",
    "* AveBedrms: No parece haber una dependencia importante en la variable objetivo con la edad promedio de las casas. Se puede observar un ligero decrecimiento en la mediana para los últimos 3 cuantiles.\n",
    "* Population: No parece haber una dependencia importante en la variable objetivo con la población. Se puede observar una disminución en la dispersión para los últimos cuantiles lo que indica que para se alcanzan precios menores que para el resto.\n",
    "* AveOccup: Se observa una ligera disminución en la mediana para cada cuantil, además de una disminución en la dispersión. Esto permite intuir que debe haber una dependencia decreciente entre la variable objetivo y la ocupación promedio.\n",
    "* Latitude: Se puede observar que para los cuantiles 4 y 7 la variable objetivo tiende a ser menor que para el resto de los cuantiles.\n",
    "* Longitude: Se puede observar que para los cuantiles 2, 3 y 7 la variable objetivo tiende a ser menor que para el resto de los cuantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize=(16, 10))  \n",
    "for i in range(len(features)):\n",
    "    row = i // 4  # Calculate the row index\n",
    "    col = i % 4   # Calculate the column index\n",
    "    X['quantile'] = pd.qcut(X[features[i]], 8)\n",
    "    sns.boxplot(X, x=X['quantile'], y=y, ax=axs[row,col])\n",
    "    axs[row, col].grid()\n",
    "    axs[row, col].set_axisbelow(True)  # Set the grid behind the plot\n",
    "    # Add y-axis label only for the first column in each row\n",
    "    if col == 0:\n",
    "        axs[row, col].set_ylabel(\"MedHouseVal\")\n",
    "    axs[row, col].set_xlabel(features[i])  # Add subplot title\n",
    "    axs[row, col].set_xticklabels(axs[row, col].get_xticks())\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las conclusiones anteriores, creemos que el orden de importancia (de mayor a menor) es el siguiente:\n",
    "1. MedInc\n",
    "2. AveRooms\n",
    "3. Longitude y Latitude (tienen igual peso)\n",
    "4. AveOccup\n",
    "5. HouseAge\n",
    "6. Population\n",
    "7. AveBedrms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 3 - Regresión Lineal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Consigna: inicio.\n",
    "\n",
    "1. Seleccione **un solo atributo** que considere puede ser el más apropiado.\n",
    "2. Instancie una regresión lineal de **scikit-learn**, y entrénela usando sólo el atributo seleccionado.\n",
    "3. Evalúe, calculando error cuadrático medio para los conjuntos de entrenamiento y evaluación.\n",
    "4. Grafique el modelo resultante, junto con los puntos de entrenamiento y evaluación.\n",
    "5. Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido.\n",
    "\n",
    "**Observación:** Con algunos atributos se puede obtener un error en test menor a 50.\n",
    "\n",
    "> Consigna: fin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se selecciona la columna MedInc, considerada la más importante para la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'MedInc'  # selecciono el atributo 'MedInc'\n",
    "X_train_f = X_train[feature]\n",
    "X_train_f = X_train_f.values.reshape(-1, 1)\n",
    "X_test_f = X_test[feature]\n",
    "X_test_f = X_test_f.values.reshape(-1, 1)\n",
    "X_train_f.shape, X_test_f.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se instancia una regresión lineal de scikit-learn y se entrena con el atributo seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()  # el bias ya esta como feature\n",
    "lr.fit(X_train_f, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa el modelo utilizando el set de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lr.predict(X_train_f)\n",
    "train_error = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = lr.predict(X_test_f)\n",
    "test_error = mean_squared_error(y_test, y_pred_test)\n",
    "print(f'Error de entrenamiento: {train_error}')\n",
    "print(f'Error de testeo: {test_error}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se grafica el modelo resultante, junto con los puntos de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = min(np.min(X_train_f), np.min(X_test_f))\n",
    "x_end = max(np.max(X_train_f), np.max(X_test_f))\n",
    "x = np.linspace(x_start, x_end, 200).reshape(-1, 1)\n",
    "\n",
    "plt.plot(x, lr.predict(x), color=\"tomato\", label=\"modelo\")\n",
    "plt.scatter(X_train_f, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"Entrenamiento\")\n",
    "plt.scatter(X_test_f, y_test, facecolor=\"white\", edgecolor=\"k\", label=\"Evaluación\")\n",
    "plt.title(feature)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 4 - Regresión Polinomial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Consigna: inicio.\n",
    "\n",
    "En este ejercicio deben entrenar regresiones polinomiales de diferente complejidad, siempre usando **scikit-learn**.\n",
    "\n",
    "Deben usar **el mismo atributo** seleccionado para el ejercicio anterior.\n",
    "\n",
    "1. Para varios grados de polinomio, haga lo siguiente:\n",
    "    1. Instancie y entrene una regresión polinomial.\n",
    "    2. Prediga y calcule error en entrenamiento y evaluación. Imprima los valores.\n",
    "    3. Guarde los errores en una lista.\n",
    "2. Grafique las curvas de error en términos del grado del polinomio.\n",
    "3. Interprete la curva, identificando el punto en que comienza a haber sobreajuste, si lo hay.\n",
    "4. Seleccione el modelo que mejor funcione, y grafique el modelo conjuntamente con los puntos.\n",
    "5. Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido.\n",
    "\n",
    "**Observación:** Con algunos atributos se pueden obtener errores en test menores a 40 e incluso a 35.\n",
    "\n",
    "> Consigna: fin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a seguir usando el atributo MedInc como en el ejercicio anterior, pero estudiaremos qué ocurre a medida que aumentamos el grado del polinomio regresor. Hacemos entonces un barrido del grado del polinomio, obteniendo el error cuadrático medio (MSE) para cada caso, tanto en el set de entrenamiento como en el de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Err_train = []\n",
    "Err_test = []\n",
    "degrees = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40, 50, 75, 100]\n",
    "\n",
    "for degree in degrees:\n",
    "    # Entrenamiento\n",
    "    lr = LinearRegression()\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    Z_train = poly.fit_transform(X_train_f, y_train)\n",
    "    lr.fit(Z_train, y_train)\n",
    "    \n",
    "    # Predicción\n",
    "    y_pred_train = lr.predict(Z_train)\n",
    "    Z_test = poly.fit_transform(X_test_f, y_test)\n",
    "    y_pred_test = lr.predict(Z_test)\n",
    "\n",
    "    # Métricas\n",
    "    Err_train.append(mean_squared_error(y_train, y_pred_train))\n",
    "    Err_test.append(mean_squared_error(y_test, y_pred_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos ahora la variación del MSE en función del grado del polinomio, para ambos conjuntos de datos. Vemos que rápidamente el valor de MSE cae al comienzo. Luego, la disminución continua, pero de manera más gradual hasta el grado 15. Hasta acá las diferencias entre el conjunto de entrenamiento y el de evaluación son pequeñas, siendo mayores para el caso de evaluación, como era de esperarse. A partir de ahí pega un primer salto, donde las curvas de entrenamiento y evalación crecen en paralelo hasta el grado 40, donde el MSE del conjunto de entrenamiento alcanza un *plateau*, mientras que el del conjunto de evaluación sigue creciendo paulatinamente hasta que se dispara alrededor del grado 75. Observamos entonces que se presenta sobreajuste a partir del grado 40.\n",
    "\n",
    "Ahora, para elegir el grado óptimo del polinomimo, nos centraremos en la región con grado menor a 16, donde los errores son menores. Si bien el mínimo estricto de la curva de entrenamiento se alcanza con grado 10, observamos que la diferencia no es significativa respecto al error del polinomio de grado 7. Recurriendo a la navaja de Ockham, consideramos entonces que el mejor modelo es con grado 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(18, 5))\n",
    "\n",
    "axs[0].plot(degrees, Err_train, color=\"blue\", label=\"Entrenamiento\")\n",
    "axs[0].plot(degrees, Err_test, color=\"red\", label=\"Evaluación\")\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel(\"Grado del polinomio\")\n",
    "axs[0].set_ylabel(\"MSE\")\n",
    "axs[0].set_xlim(-2, 102)\n",
    "axs[0].set_ylim(0, 12)\n",
    "\n",
    "axs[1].plot(degrees, Err_train, color=\"blue\", label=\"Entrenamiento\")\n",
    "axs[1].plot(degrees, Err_test, color=\"red\", label=\"Evaluación\")\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel(\"Grado del polinomio\")\n",
    "axs[1].set_ylabel(\"MSE\")\n",
    "axs[1].set_xlim(30, 80)\n",
    "axs[1].set_ylim(1.1, 2)\n",
    "\n",
    "axs[2].plot(degrees, Err_train, color=\"blue\", label=\"Entrenamiento\")\n",
    "axs[2].plot(degrees, Err_test, color=\"red\", label=\"Evaluación\")\n",
    "axs[2].legend()\n",
    "axs[2].set_xlabel(\"Grado del polinomio\")\n",
    "axs[2].set_ylabel(\"MSE\")\n",
    "axs[2].set_xlim(0, 16)\n",
    "axs[2].set_ylim(0.66, 0.72)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a entrenar el modelo, pero fijando el grado en 7, para así graficar los resultados.\n",
    "\n",
    "\n",
    "**FALTA**\n",
    "Interprete el resultado, haciendo algún comentario sobre las cualidades del modelo obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo\n",
    "degree = 7\n",
    "lr = LinearRegression()\n",
    "poly = PolynomialFeatures(degree)\n",
    "Z_train = poly.fit_transform(X_train_f, y_train)\n",
    "lr.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, lr.predict(poly.fit_transform(x)), color=\"tomato\", label=\"modelo\")\n",
    "plt.scatter(X_train_f, y_train, facecolor=\"dodgerblue\", edgecolor=\"k\", label=\"Entrenamiento\")\n",
    "plt.scatter(X_test_f, y_test, facecolor=\"white\", edgecolor=\"k\", label=\"Evaluación\")\n",
    "plt.title(feature)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ejercicio 5 - Regresión con más de un Atributo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Consigna: inicio.\n",
    "\n",
    "En este ejercicio deben entrenar regresiones que toman más de un atributo de entrada.\n",
    "\n",
    "1. Seleccione **dos o tres atributos** entre los más relevantes encontrados en el ejercicio 2.\n",
    "2. Repita el ejercicio anterior, pero usando los atributos seleccionados. No hace falta graficar el modelo final.\n",
    "3. Interprete el resultado y compare con los ejercicios anteriores. ¿Se obtuvieron mejores modelos? ¿Porqué?\n",
    "\n",
    "> Consigna: fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Resolver acá. Ayuda (con dos atributos):\n",
    "selector = (np.array(california['feature_names']) == 'HouseAge') | (np.array(california['feature_names']) == 'AveRooms')\n",
    "\n",
    "X_train_fs = X_train[:, selector]\n",
    "X_test_fs = X_test[:, selector]\n",
    "X_train_fs.shape, X_test_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Resolver acá."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**3. Responder acá.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
